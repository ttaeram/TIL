# Chapter 08: 성능 최적화
## 03. 하이퍼 파라미터를 이용한 성능 최적화
- 하이퍼파라미터를 이용한 성능 최적화의 추가적인 방법으로 배치 정규화, 드롭아웃, 조기 종료가 있다.

### 3-1. 배차 정규화를 이용한 성능 최적화
- 배치 정규화를 진행하기에 앞서 유사한 의미로 사용되는 용어들을 알아본다.

#### 1. 정규화
- 정규화(normalization)는 데이터 범위를 사용자가 원하는 범위로 제한하는 것을 의미한다.
- 예를 들어 이미지 데이터는 픽셀 정보로 0~255 사이의 값을 갖는데, 이를 255로 나누면 0~1.0 사이의 값을 갖게 된다.

![](./assets/Ch08-2/deeplearning01.jpg)

- 정규화는 각 특성 범위(스케일(scale))를 조정한다는 의미로 특성 스케일링(feature scaling)이라고도 한다.
- 스케일 조정을 위해 MinMaxScaler() 기법을 사용하므로 수식은 다음과 같다.

![](./assets/Ch08-2/formula01.jpg)

#### 2. 규제화
- 규제화(regularization)는 모델 복잡도를 줄이기 위해 제약을 두는 방법이다.
- 이때 제약은 데이터가 네트워크에 들어가기 전에 필터를 적용한 것이라고 생각하면 된다.
- 예를 들어 다음 왼쪽 그림은 필터가 적용되지 않을 경우 모든 데이터가 네트워크에 투입되지만, 오른쪽 그림은 필터로 걸러진 데이터만 네트워크에 투입되어 빠르고 정확한 결과를 얻을 수 있다.

![](./assets/Ch08-2/deeplearning02.jpg)

- 규제를 이용하여 모델 복잡도를 줄이는 방법:
    - 드롭아웃
    - 조기 종료

#### 3. 표준화
- 표준화(standardization)는 기존 데이터를 평균은 0, 표준편차는 1인 형태의 데이터로 만드는 방법이다.
- 다른 표현으로 표준화 스칼라(standard scaler) 혹은 z-스코어 정규화(z-score normalization)라고도 한다.

![](./assets/Ch08-2/deeplearning03.jpg)

- 평균을 기준으로 얼마나 떨어져 있는지 살펴볼 때 사용한다.
- 보통 데이터 분포가 가우시안 분포를 따를 때 유용한 방법으로 다음 수식을 사용한다.

![](./assets/Ch08-2/formula02.jpg)

#### 4. 배치 정규화
- 배치 정규화(batch normalization)는 2015년 “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift” 논문에 설명되어 있는 기법으로, 데이터 분포가 안정되어 학습 속도를 높일 수 있다.
- 배치 정규화는 기울기 소멸(gradient vanishing)이나 기울기 폭발(gradient exploding) 같은 문제를 해결하기 위한 방법이다.
- 일반적으로 기울기 소멸이나 폭발 문제를 해결하기 위해 손실 함수로 렐루(ReLU)를 사용하거나 초깃값 튜닝, 학습률(learning rate) 등을 조정한다.

> #### 기울기 소멸과 기울기 폭발
> - 기울기 소멸: 오차 정보를 역전파시키는 과정에서 기울기가 급격히 0에 가까워져 학습이 되지 않는 현상
> - 기울기 폭발: 학습 과정에서 기울기가 급격히 커지는 현상
>
> ![](./assets/Ch08-2/deeplearning04.jpg)

![](./assets/Ch08-2/deeplearning05.jpg)

- 배치 정규화가 소개된 논문에 따르면 기울기 소멸과 폭발 원인은 내부 공변량 변화(internal covariance shift) 때문인데, 이것은 네트워크의 각 층마다 활성화 함수가 적용되면서 입력 값들의 분포가 계속 바뀌는 현상을 의미한다.
- 따라서 분산된 분포를 정규분포로 만들기 위해 표준화와 유사한 방식을 미니 배치(mini-batch)에 적용하여 평균은 0으로, 표준편차는 1로 유지하도록 하며 수식은 다음과 같다.

![](./assets/Ch08-2/formula03.jpg)

![](./assets/Ch08-2/formula04.jpg)

1. 미니 배치 평균을 구한다.
2. 미니 배치의 분산과 표준편차를 구한다.
3. 정규화를 수행한다.
4. 스케일(scale)을 조정(데이터 분포 조정)한다.

- 따라서 매 단계마다 활성화 함수를 거치면서 데이터셋 분포가 일정해지기 때문에 속도를 향상시킬 수 있지만 다음과 같은 단점도 있다.
- 첫째, 배치 크기가 작을 때는 정규화 값이 기존 값과 다른 방향으로 훈련될 수 있다. 예를 들어 분산이 0이면 정규화 자체가 안 되는 경우가 생길 수 있다.
- 둘째, RNN은 네트워크 계층별로 미니 정규화를 적용해야 하기 때문에 모델이 더 복잡해지면서 비효율적일 수 있다.
- 따라서 이러한 문제들을 해결하기 위한 가중치 수정, 네트워크 구성 변경 등을 수행하지만, 무엇보다 중요한 것은 배치 정규화를 적용하면 적용하지 않았을 때보다 성능이 좋아지기 때문에 많이 사용된다.

### 3-2. 드롭아웃을 이용한 성능 최적화
- 과적합은 훈련 데이터셋을 과하게 학습하는 것을 의미한다.
- 그렇다면 과하게 훈련 데이터셋을 학습하는 것이 왜 문제일까?
- 일반적으로 훈련 데이터셋은 실제 데이터셋의 부분 집합이므로 훈련 데이터셋에 대해서는 오류가 감소하지만, 테스트 데이터셋에 대해서는 오류가 증가한다.
- 즉, 훈련 데이터셋에 대해 훈련을 계속한다면 오류는 줄어들지만 테스트 데이터셋에 대한 오류는 어느 순간부터 증가하는데, 이러한 모델을 과적합되어 있다고 한다.

![](./assets/Ch08-2/deeplearning06.jpg)

- 드롭아웃(dropout)이란 훈련할 때 일정 비율의 뉴런만 사용하고, 나머지 뉴런에 해당하는 가중치는 업데이트하지 않는 방법이다.
- 물론 매 단계마다 사용하지 않는 뉴런을 바꾸어 가며 훈련시킨다.
- 즉, 드롭아웃은 노드를 임의로 끄면서 학습하는 방법으로, 은닉층에 배치된 노드 중 일부를 임의로 끄면서 학습한다.
- 꺼진 노드는 신호를 전달하지 않으므로 지나친 학습을 방지하는 효과가 생긴다.

![](./assets/Ch08-2/deeplearning07.jpg)

- 위 그림의 왼쪽은 일반적인 신경망이고, 오른쪽은 드롭아웃이 적용된 신경망의 모습이다.
- 일부 노드들은 비활성화되고 남은 노드들로 신호가 연결되는 신경망 형태를 띠고 있다.
- 어떤 노드를 비활성화할지는 학습할 때마다 무작위로 선정되며, 테스트 데이터로 평가할 때는 노드들을 모두 사용하여 출력하되 노드 삭제 비율(드롭아웃 비율)을 곱해서 성능을 평가한다.
- 드롭아웃을 사용하면 훈련 시간이 길어지는 단점이 있지만, 모델 성능을 향상하기 위해 상당히 자주 쓰는 방법이다.

### 3-2-1. 배치 정규화와 드롭아웃에 대한 파이토치 예제
- 여기에서 사용되는 데이터셋은 파이토치 torchvision.datasets에서 제공하는 FashionMNIST 데이터셋이다.
- 먼저 필요한 라이브러리를 호출한다.
```py
# 8-1 라이브러리 호출

import torch
import matplotlib.pyplot as plt
import numpy as np

import torchvision
import torchvision.transforms as transforms

import torch.nn as nn
import torch.optim as optim
```
- 예제에서 사용할 FashionMNIST 데이터셋을 내려받는다.
```py
# 8-2 데이터셋 내려받기

trainset = torchvision.datasets.FashionMNIST(
                            root='/Users/ramy/PycharmProjects/Pytorch/080289/chap08/data/', train=True,
                            download=True,
                            transform=transforms.ToTensor())
```
- 내려받은 데이터셋을 메모리로 가져온다.
- 단 trainloader 변수가 호출될 때 메모리로 가져오게 된다.
```py
# 8-3 데이터셋을 메모리로 가져오기

batch_size = 4
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)
```
- batch_size를 4로 설정했기 때문에 데이터를 메모리로 가져올 때 한 번에 네 개씩 쪼개서 가져온다.
- 이제 데이터셋을 이미지와 레이블로 분리하여 학습을 위한 준비를 한다.
- 분리된 데이터셋에 대한 정보를 확인해 본다.
```py
# 8-4 데이터셋 분리

dataiter = iter(trainloader)
images, labels = next(dataiter)

print(images.shape)
print(images[0].shape)
print(labels[0].item())
```
- 이미지와 레이블로 분리된 데이터의 크기를 각각 출력
```
torch.Size([4, 1, 28, 28])
torch.Size([1, 28, 28])
3
```

#### 출력의 크기가 의미하는 내용

![](./assets/Ch08-2/code01.jpg)

- a: 한 번의 배치 크기로 몇 개의 데이터를 가져오는지 의미한다. 앞에서 batch_size = 4를 지정했기 때문에 4를 출력했다.
- b: 채널을 의미하는 것으로 흑백 이미지는 1을 출력하며, 컬러 이미지는 3을 출력한다.
- c: 28×28(너비×높이) 픽셀 크기의 이미지라는 의미이다.

---
- 예제에서 사용하고 있는 데이터셋의 이미지 몇 개만 출력해 본다.
- 먼저 이미지 출력을 위해 데이터 형태를 바꾸어 주기 위한 전처리 함수를 생성한다.
```py
# 8-5 이미지 데이터를 출력하기 위한 전처리

def imshow(img, title):
    # 출력할 개별 이미지의 크기 지정
    plt.figure(figsize=(batch_size * 4, 4))
    plt.axis('off')
    # (1)
    plt.imshow(np.transpose(img, (1, 2, 0)))
    plt.title(title)
    plt.show()
```

#### (1)
- 기본적으로 파이토치는 이미지 데이터셋을 [배치 크기, 채널, 너비, 높이(batch size, channel, width, height)] 순서대로 저장한다.
- 하지만 이를 맷플롯립(matplotlib)으로 출력하기 위해서는 이미지가 [너비, 높이, 채널] 형태이어야 한다.
- 즉, 데이터의 형태 변경이 필요한데, 이때 사용할 수 있는 것이 넘파이 라이브러리의 transpose()이다.

---
- 이제 이미지 출력을 위한 그래프 방식을 정의한다.
```py
# 8-6 이미지 데이터 출력 함수

def show_batch_images(dataloader):
    # 이미지의 크기는 (4, 28, 28, 1(배치 크기, 높이, 너비, 채널))이 됨
    images, labels = next(iter(dataloader))
    
    # 좌표에 이미지 픽셀을 대응시켜 그리드 형태로 출력
    img = torchvision.utils.make_grid(images)
    # imshow 함수를 사용함으로써 데이터의 형태는 (채널, 높이, 너비)에서 (높이, 너비, 채널)로 변경됨
    imshow(img, title=[str(x.item()) for x in labels])

    return images, labels
```
- 앞에서 생성한 함수를 이용하여 이미지를 출력해 본다.
```py
# 8-7 이미지 출력

images, labels = show_batch_images(trainloader)
```
- 이미지 출력 결과:

![](./assets/Ch08-2/deeplearning08.jpg)

- 가장 상위에 표시된 숫자는 클래스(레이블)를 의미하며 그 내용은 다음과 같다.
```
classes = {
    0: "T-Shirt/Top",
    1: "Trouser",
    2: "Pullover",
    3: "Dress",
    4: "Coat",
    5: "Sandal",
    6: "Shirt",
    7: "Sneaker",
    8: "Bag",
    9: "Ankle Boot"
    }
```
- 또한, 네 개의 이미지가 출력되는 이유는 한 번의 배치에서 네 개의 이미지만 가져오도록 했기 때문이다.
- 이제 모델의 네트워크를 구축해야 한다.
- 배치 정규화가 적용된 모델과 비교를 위해 배치 정규화가 적용되지 않는 모델을 먼저 생성해 본다.
```py
# 8-8 배치 정규화가 적용되지 않은 네트워크

class NormalNet(nn.Module):
    def __init__(self):
        super(NormalNet, self).__init__()
        # nn.Sequential을 사용하면 forward( ) 함수에서 계층(layer)별로 가독성 있게 코드 구현이 가능
        self.classifier = nn.Sequential(
            # (28, 28) 크기의 이미지로 입력은 784(28×28) 크기가 됨
            nn.Linear(784, 48),
            nn.ReLU(),
            nn.Linear(48, 24),
            nn.ReLU(),
            # FashionMNIST의 클래스는 총 열 개
            nn.Linear(24, 10)
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)
        # nn.Sequential에서 정의한 계층 호출
        x = self.classifier(x)
        return x
```
- 이번에는 배치 정규화가 포함된 네트워크를 구축한다.
```py
# 8-9 배치 정규화가 포함된 네트워크

class BNNet(nn.Module):
    def __init__(self):
        super(BNNet, self).__init__()
        self.classifier = nn.Sequential(
            nn.Linear(784, 48),
            # (1)
            nn.BatchNorm1d(48),
            nn.ReLU(),
            nn.Linear(48, 24),
            nn.BatchNorm1d(24),
            nn.ReLU(),
            nn.Linear(24, 10)
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x
```
- (1): 배치 정규화가 적용되는 부분이다. BatchNorm1d에서 사용되는 파라미터는 특성 개수로 이전 계층의 출력 채널이 된다.
---
- 배치 정규화를 사용하는 이유는 은닉층에서 학습이 진행될 때마다 입력 분포가 변하면서 가중치가 엉뚱한 방향으로 갱신되는 문제가 종종 발생하기 때문이다.
- 즉, 신경망의 층이 깊어질수록 학습할 때 가정했던 입력 분포가 변화하여 엉뚱한 학습이 진행될 수 있는데 배치 정규화를 적용해서 입력 분포를 고르게 맞추어 줄 수 있다.

![](./assets/Ch08-2/deeplearning09.jpg)

- 배치 정규화는 아래와 같은 위치에 놓여야 한다.

![](./assets/Ch08-2/deeplearning10.jpg)

- 배치 정규화가 적용되지 않은 모델을 선언(객체화)한다.
```py
# 8-10 배치 정규화가 적용되지 않은 모델 선언

model = NormalNet()
print(model)
```
- 코드를 실행하면 다음과 같이 배치 정규화가 적용되지 않은 모델의 네트워크가 출력된다.
```
NormalNet(
  (classifier): Sequential(
    (0): Linear(in_features=784, out_features=48, bias=True)
    (1): ReLU()
    (2): Linear(in_features=48, out_features=24, bias=True)
    (3): ReLU()
    (4): Linear(in_features=24, out_features=10, bias=True)
  )
)
```
- 배치 정규화가 적용된 모델을 선언(객체화)한다.
```py
# 8-11 배치 정규화가 적용된 모델 선언

model_bn = BNNet()
print(model_bn)
```
- 배치 정규화가 적용된 모델의 네트워크가 출력된다.
```
BNNet(
  (classifier): Sequential(
    (0): Linear(in_features=784, out_features=48, bias=True)
    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=48, out_features=24, bias=True)
    (4): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=24, out_features=10, bias=True)
  )
)
```
- 데이터로더를 이용하여 앞에서 내려받았던 데이터셋을 메모리로 불러올 준비를 한다.
- 참고로 앞에서도 메모리로 불러오는 부분을 진행했다.
- 그때는 이미지 출력을 위한 용도로 배치 크기를 4로 설정했지만, 이번에 메모리로 불러오는 것은 학습을 위한 용도로 배치 크기를 512로 지정한다.
```py
# 8-12 데이터셋 메모리로 불러오기

batch_size = 512
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)
```
- 모델에서 사용할 옵티마이저와 손실 함수를 지정한다.
```py
# 8-13 옵티마이저, 손실 함수 지정

loss_fn = nn.CrossEntropyLoss()
opt = optim.SGD(model.parameters(), lr=0.01)
opt_bn = optim.SGD(model_bn.parameters(), lr=0.01)
```
- 모델을 학습시킨다.
```py
# 8-14 모델 학습

loss_arr = []
loss_bn_arr = []
max_epochs = 2

for epoch in range(max_epochs):
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        # 배치 정규화가 적용되지 않은 모델의 학습
        opt.zero_grad()
        outputs = model(inputs)
        loss = loss_fn(outputs, labels)
        loss.backward()
        opt.step()

        # 배치 정규화가 적용된 모델의 학습
        opt_bn.zero_grad()
        outputs_bn = model_bn(inputs)
        loss_bn = loss_fn(outputs_bn, labels)
        loss_bn.backward()
        opt_bn.step()

        loss_arr.append(loss.item())
        loss_bn_arr.append(loss_bn.item())

    plt.plot(loss_arr, 'yellow', label='Normal')
    plt.plot(loss_bn_arr, 'blue', label='BatchNorm')
    plt.legend()
    plt.show()
```
- 다음 그림들은 모델 학습 결과(오차 정보)를 보여 준다.
- 모델 학습 결과는 배치 정규화가 적용된 모델(아래 그림의 파란색 그래프)과 적용되지 않은 모델(아래 그림의 노란색 그래프)을 그래프로 출력한다.
- 출력된 전체 이미지에서 앞뒤 두 개씩만 책에 담았지만 주피터 노트북 예제 파일을 통해 전체 결과를 확인할 수 있다.

![](./assets/Ch08-2/deeplearning11.jpg)

![](./assets/Ch08-2/deeplearning12.jpg)

- 배치 정규화가 적용된 모델과 적용되지 않은 모델의 오차에 대한 그래프 결과가 어떤가?
- 둘 다 시간이 흐를수록 오차가 줄어드는 것을 확인할 수 있다.
- 하지만 오차가 줄어드는 범위 및 값의 차이는 명백하다.
- 배치 정규화가 적용된 모델의 경우 더 낮은 값으로 안정적인 범위 내에서 줄어들고 있는 것을 확인할 수 있다.
- 즉, 다른 말로 표현하면 배치 정규화가 적용된 모델은 에포크가 진행될수록 오차도 줄어들면서 안정적인 학습을 하고 있다고 할 수 있다.
---
- 배치 정규화가 성능에 어떤 영향을 미치는지 확인했다면 이번에는 드롭아웃에 대해 살펴본다.
- 드롭아웃을 알아보기에 앞서 훈련과 테스트 데이터셋이 어떻게 분포하는지 알아본다.
```py
# 8-15 데이터셋의 분포를 출력하기 위한 전처리

N = 50
noise = 0.3

# (1)
x_train = torch.unsqueeze(torch.linspace(-1, 1, N), 1)
# (2)
y_train = x_train + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))

x_test = torch.unsqueeze(torch.linspace(-1, 1, N), 1)
y_test = x_test + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))
```

#### (1)
- 훈련 데이터셋이 -1~1의 값을 갖도록 조정한다.

![](./assets/Ch08-2/code02.jpg)

- torch.linspace: 주어진 범위에서 균등한 값을 갖는 텐서를 만들기 위해 사용한다.
- torch.linspace 사용법:
```py
import torch
# 0~10을 100으로 분할
print(torch.linspace(0, 10))
print('---------------')
# 0~10을 5로 분할
print(torch.linspace(0, 10, 5))
```
- 출력 결과:
```
tensor([ 0.0000, 0.1010, 0.2020, 0.3030, 0.4040, 0.5051, 0.6061, 0.7071, 0.8081,
0.9091,  1.0101, 1.1111, 1.2121, 1.3131, 1.4141, 1.5152, 1.6162, 1.7172, 1.8182,
1.9192,  2.0202, 2.1212, 2.2222, 2.3232, 2.4242, 2.5253, 2.6263, 2.7273, 2.8283,
2.9293,  3.0303, 3.1313, 3.2323, 3.3333, 3.4343, 3.5354, 3.6364, 3.7374, 3.8384,
3.9394,  4.0404, 4.1414, 4.2424, 4.3434, 4.4444, 4.5455, 4.6465, 4.7475, 4.8485,
4.9495,  5.0505, 5.1515, 5.2525, 5.3535, 5.4545, 5.5556, 5.6566, 5.7576, 5.8586,
5.9596,  6.0606, 6.1616, 6.2626, 6.3636, 6.4646, 6.5657, 6.6667, 6.7677, 6.8687,
6.9697,  7.0707, 7.1717, 7.2727, 7.3737, 7.4747, 7.5758, 7.6768, 7.7778, 7.8788,
7.9798,  8.0808, 8.1818, 8.2828, 8.3838, 8.4848, 8.5859, 8.6869, 8.7879, 8.8889,
8.9899,  9.0909, 9.1919, 9.2929, 9.3939, 9.4950, 9.5960, 9.6970, 9.7980, 9.8990,
10.0000])
--------------- 
tensor([ 0.0000, 2.5000, 5.0000, 7.5000, 10.0000])
```
- 따라서 torch.linspace(-1, 1, N) 의미는 -1~1의 범위에서 N개의 균등한 값을 갖는 텐서를 생성하겠다는 것이다.

- torch.unsqueeze: unsqueeze()는 차원을 늘리기 위해 사용한다. 따라서 torch.unsqueeze(torch.linspace(-1, 1, N), 1) 의미는 torch.linspace(-1, 1, N) 텐서의 첫 번째 자리에 차원을 증가시키겠다는 것이다.

#### (2)
- 훈련 데이터셋 값의 범위가 정규분포를 갖도록 조정한다.

![](./assets/Ch08-2/code03.jpg)

- torch.normal: 정규분포로부터 무작위 표본 추출을 위해 사용한다. torch.normal(평균, 표준편차)를 의미하기 때문에 torch.zeros()는 평균, torch.ones()는 표준편차를 의미한다. 평균은 0, 표준편차는 1이 기본값이다.
- torch.zeros: 0 값을 갖는 N×1 텐서를 생성한다.
- torch.ones: 1 값을 갖는 N×1 텐서를 생성한다.

---
- 앞에서 전처리된 데이터를 그래프로 출력하여 분포를 확인한다.
```py
# 8-16 데이터 분포를 그래프로 출력

# (1)
plt.scatter(x_train.data.numpy(), y_train.data.numpy(), c='purple', alpha=0.5, label='train')
plt.scatter(x_test.data.numpy(), y_test.data.numpy(), c='yellow', alpha=0.5, label='test')
plt.legend()
plt.show()
```

#### (1)
- plt.scatter()는 데이터를 그래프상에 점(point)으로 출력해서 데이터 분포를 확인하고자 할 때 사용한다.

![](./assets/Ch08-2/code04.jpg)

- 사용된 파라미터:
    - 첫 번째 파라미터: x축에 위치할 데이터
    - 두 번째 파라미터: y축에 위치할 데이터
    - c: 그래프로 출력되는 마커(그래프에서 작은 동그라미/점)의 색상
    - alpha: 마커에 대한 투명도를 조절하는 것으로 alpha=1이면 완전 불투명 상태를 의미한다.
    - label: 맷플롯립의 레전드와 같은 역할을 하지만 plt.legend()와 함께 사용되어야 한다.

---
- 다음 그림은 데이터의 분포를 그래프로 출력한 결과이다.

![](./assets/Ch08-2/deeplearning13.jpg)

- 훈련과 테스트 데이터가 고르게 분포되어 있는 것을 확인할 수 있다.
- 드롭아웃의 효과를 확인하기 위해 드롭아웃이 적용된 것과 그렇지 않은 것의 모델을 생성한다.
```py
# 8-17 드롭아웃을 위한 모델 생성

N_h = 100
# 드롭아웃이 적용되지 않은 모델
model = torch.nn.Sequential(
    torch.nn.Linear(1, N_h),
    torch.nn.ReLU(),
    torch.nn.Linear(N_h, N_h),
    torch.nn.ReLU(),
    torch.nn.Linear(N_h, 1),
)

# 드롭아웃이 적용된 모델
model_dropout = torch.nn.Sequential(
    torch.nn.Linear(1, N_h),
    # 드롭아웃 적용
    torch.nn.Dropout(0.2),
    torch.nn.ReLU(),
    torch.nn.Linear(N_h, N_h),
    torch.nn.Dropout(0.2),
    torch.nn.ReLU(),
    torch.nn.Linear(N_h, 1),
)
```
- 앞에서 생성한 모델을 위한 옵티마이저와 손실 함수를 지정한다.
```py
# 8-18 옵티마이저와 손실 함수 지정

opt = torch.optim.Adam(model.parameters(), lr=0.01)
opt_dropout = torch.optim.Adam(model_dropout.parameters(), lr=0.01)
loss_fn = torch.nn.MSELoss()
```
- 이제 드롭아웃이 적용된 모델과 그렇지 않은 모델을 학습시키고 오차를 그래프로 출력한다.
```py
# 8-19 모델 학습

max_epochs = 1000
for epoch in range(max_epochs):
    # 드롭아웃이 적용되지 않은 모델 학습
    pred = model(x_train)
    loss = loss_fn(pred, y_train)
    opt.zero_grad()
    loss.backward()
    opt.step()

    # 드롭아웃이 적용된 모델 학습
    pred_dropout = model_dropout(x_train)
    loss_dropout = loss_fn(pred_dropout, y_train)
    opt_dropout.zero_grad()
    loss_dropout.backward()
    opt_dropout.step()

    # epoch를 50으로 나눈 나머지가 0이면 다음 진행
    if epoch % 50 == 0:
        model.eval()
        model_dropout.eval()

        test_pred = model(x_test)
        test_loss = loss_fn(test_pred, y_test)

        test_pred_dropout = model_dropout(x_test)
        test_loss_dropout = loss_fn(test_pred_dropout, y_test)

        plt.scatter(x_train.data.numpy(), y_train.data.numpy(), c='purple', alpha=0.5, label='train')
        plt.scatter(x_test.data.numpy(), y_test.data.numpy(), c='yellow',  alpha=0.5, label='test')
        # 파란색 실선으로 x축은 테스트 데이터셋, y축은 드롭아웃이 적용되지 않은 모델의 결과를 그래프로 출력
        plt.plot(x_test.data.numpy(), test_pred.data.numpy(), 'b-', lw=3, label='normal')
        # 초록색 점선으로 x축은 테스트 데이터셋, y축은 드롭아웃이 적용된 모델의 결과를 그래프로 출력
        plt.plot(x_test.data.numpy(), test_pred_dropout.data.numpy(), 'g--', lw=3, label='dropout')
        # 에포크, 드롭아웃이 적용되지 않은 모델의 오차, 드롭아웃이 적용된 모델의 오차를 타이틀로 출력
        plt.title('Epoch %d, Loss=%0.4f, Loss with dropout=%0.4f' % (epoch, test_loss, test_loss_dropout))
        plt.legend()
        model.train()
        model_dropout.train()
        plt.pause(0.05)
```
- 다음 그림들은 드롭아웃과 관련된 모델 학습 결과이다.
- 책에는 앞뒤로 두 개에 대한 출력만 실었지만 주피터 노트북 예제 파일에서 전체 결과를 확인할 수 있다.

![](./assets/Ch08-2/deeplearning14.jpg)

![](./assets/Ch08-2/deeplearning15.jpg)

- 전반적으로 오차가 줄어드는 범위는 크지 않다.
- 하지만 드롭아웃을 적용했을 때의 오차가 더 낮은 것을 확인할 수 있다.
- 이제 그래프를 자세히 살펴보자.
- 출력 결과에서 초록색 점선(드롭아웃이 적용된 모델)과 파란색 실선(드롭아웃이 적용되지 않은 모델)의 차이가 크지 않아 보일 수 있지만 이 정도면 실제로는 큰 차이가 있는 상태이다.
- 훈련 횟수가 늘어날수록 파란색 실선은 가장자리의 자주색 점들을 찾아가고 있다.
- 문제는 자주색 선이 훈련 데이터셋을 의미한다는 것이고, 이것은 다른 의미로 과적합 현상을 보이고 있다는 것이다.
- 과적합이 발생하는 모델은 훈련 데이터에 대한 정확도는 높을 수 있지만 새로운 데이터, 즉 검증 데이터나 테스트 데이터에 대해서는 제대로 동작하지 않는 문제가 있다.
- 이와 같이 과적합 현상을 방지하기 위해 드롭아웃을 사용하며, 초록색 점선 그래프에서는 과적합 현상이 발생하지 않는 것을 확인할 수 있다.

### 3-3. 조기 종료를 이용한 성능 최적화
- 조기 종료(early stopping)는 뉴럴 네트워크가 과적합을 회피하는 규제 기법이다.
- 훈련 데이터와 별도로 검증 데이터를 준비하고, 매 에포크마다 검증 데이터에 대한 오차(validation loss)를 측정하여 모델의 종료 시점을 제어한다.
- 즉, 과적합이 발생하기 전까지 학습에 대한 오차(training loss)와 검증에 대한 오차 모두 감소하지만, 과적합이 발생하면 훈련 데이터셋에 대한 오차는 감소하는 반면 검증 데이터셋에 대한 오차는 증가한다.
- 따라서 조기 종료는 검증 데이터셋에 대한 오차가 증가하는 시점에서 학습을 멈추도록 조정한다.

![](./assets/Ch08-2/deeplearning16.jpg)

- 조기 종료는 학습을 언제 종료시킬지 결정할 뿐이지 최고의 성능을 갖는 모델을 보장하지는 않는다는 점에 주의해야 한다.
- 이번 예제는 조기 종료뿐만 아니라 학습률(learning rate)을 조정해서 성능을 향상시키는 방법에 대해서도 함께 알아본다.

- 먼저 필요한 라이브러리들을 호출한다.
```py
# 8-20 라이브러리 호출

import torch
import torch.nn as nn
import torch.optim as optim
# 사전 학습된 모델을 이용하고자 할 때 사용하는 라이브러리
import torchvision.models as models
from torchvision import transforms, datasets

import matplotlib
import matplotlib.pyplot as plt
import time
import argparse
from tqdm import tqdm
# 출력 그래프에서 격자로 숫자 범위가 눈에 잘 띄도록 하는 스타일
matplotlib.style.use('ggplot')
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```
- 앞에서 설정했던 GPU 사용을 위한 코드이다.
- 최근 높은 GPU 가격 때문에 GPU가 장착되어 있지 않은 서버/PC가 많을 수 있다.
- 하지만 걱정할 필요는 없다.
- 파이토치는 CPU에서도 잘 실행되며 책에서 다루는 예제들도 CPU만으로도 충분히 사용할 수 있도록 구성되어 있다.
- 다음은 데이터셋 전처리를 위한 항목들을 정의한다.
- 전처리에는 데이터 크기 조정 및 데이터 정규화(분포 조정) 등이 포함된다.
```py
# 8-21 데이터셋 전처리

train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
```
- 예제에서 사용하는 데이터셋은 핫도그와 핫도그가 아닌 이미지들을 사용한다.
- 데이터셋은 https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog에서 내려받을 수 있지만 이것 역시 ‘Food 101 dataset’을 이용한 것이다.
- 예제를 진행할 데이터셋을 배치 크기로 메모리로 가져오기 위한 준비를 한다.
- 일반적으로 PC에서 사용하는 메모리 용량(16~24GB)을 고려하여 한 번에 32개의 이미지를 불러오도록 설정했지만, 성능이 좋은 서버/PC라면 더 많은 이미지를 한꺼번에 불러와서 처리해도 좋다.
```py
# 8-22 데이터셋 가져오기

train_dataset = datasets.ImageFolder(
    root=r'/Users/ramy/PycharmProjects/Pytorch/080289/chap08/data/archive/train',
    transform=train_transform
)
train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=32, shuffle=True,
)
val_dataset = datasets.ImageFolder(
    root=r'/Users/ramy/PycharmProjects/Pytorch/080289/chap08/data/archive/test',
    transform=val_transform
)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=32, shuffle=False,
)
```
- 이제 모델을 생성할 텐데, 네트워크를 직접 구축하는 것이 아닌 사전 학습된 ResNet50을 사용할 예정이다.
- 6장에서 배웠듯이 사전 학습된 모델을 사용할 경우 간편하게 네트워크를 구성하고 사용할 수 있는 장점이 있다.
```py
# 8-23 모델 생성

def resnet50(pretrained=True, requires_grad=False):
    model = models.resnet50(progress=True, pretrained=pretrained)
    # 파라미터를 고정하여 backward() 중에 기울기가 계산되지 않도록 함. requires_grad=False를 파라미터로 받았기 때문에 해당 구문이 실행됨.
    if requires_grad == False:
        for param in model.parameters():
            param.requires_grad = False
    # 파라미터 값이 backward() 중에 기울기 계산에 반영됨
    elif requires_grad == True:
        for param in model.parameters():
            param.requires_grad = True
    # 마지막 분류를 위한 계층은 학습을 진행
    model.fc = nn.Linear(2048, 2)
    return model
```
- 파이토치에서 조기 종료와 함께 자주 사용되는 것으로 학습률 감소(learning rate decay)라는 것이 있다.
- 학습률에 대한 값을 고정시켜서 모델을 학습시키는 것이 아니라 학습이 진행되는 과정에서 학습률을 조금씩 낮추어 주는 성능 튜닝 기법 중에 하나이다.
- 학습률 감소는 학습률 스케줄러(learning rate scheduler)라는 것을 이용하는데, 주어진 ‘patience’ 횟수만큼 검증 데이터셋에 대한 오차 감소가 없으면 역시 주어진 ‘factor’만큼 학습률을 감소시켜서 모델 학습의 최적화가 가능하도록 도와준다.
- 다음 코드를 통해 자세히 살펴본다.
```py
# 8-24 학습률 감소

class LRScheduler():
    def __init__(
        self, optimizer, patience=5, min_lr=1e-6, factor=0.5
    ):
        self.optimizer = optimizer
        self.patience = patience
        self.min_lr = min_lr
        self.factor = factor
        # (1)
        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            patience=self.patience,
            factor=self.factor,
            min_lr=self.min_lr,
            verbose=True
        )

    def __call__(self, val_loss):
        # (2)
        self.lr_scheduler.step(val_loss)
```

#### (1)
- 학습 과정에서 모델 성능에 대한 개선이 없을 경우 학습률 값을 조절하여 모델의 개선을 유도하는 콜백 함수이다.

![](./assets/Ch08-2/code05.jpg)

- lr_scheduler.ReduceLROnPlateau: ReduceLROnPlateau는 검증 데이터셋에 대한 오차의 변동이 없으면 학습률을 factor배로 감소시킨다.
- optimizer: 파라미터(가중치)를 갱신시키는 부분으로, 여기에서는 아담(optim.Adam)을 사용한다.
- mode:
    - 언제 학습률을 조정할지에 대한 기준이 되는 값이다.
    - 만약 검증 데이터셋에 대한 오차(val_loss)를 기준으로 사용하면 오차가 더 이상 감소되지 않을 때 학습률을 조정하게 된다.
    - 이때 오차 값이 최소(min)가 되어야 하는지, 최대(max)가 되어야 하는지 알려 주는 파라미터가 mode이다.
    - 예를 들어 학습률 조정의 기준이 되는 값을 모델의 정확도(val_acc)로 사용하면 값이 클수록 좋기 때문에 'max'를 지정하고, 모델의 오차(val_loss)로 사용할 경우 작을수록 좋기 때문에 'min'을 지정한다.
    - 예제에서는 모델의 오차를 사용하기 때문에 'min'을 사용했다.
- patience: 학습률을 업데이트하기 전에 몇 번의 에포크를 기다려야 하는지 결정하는 것으로, 여기에서는 다섯 번의 에포크를 기다리도록 설정했다.
- factor:
    - 학습률을 얼마나 감소시킬지 지정하는 파라미터이다.
    - 새로운 학습률은 기존 학습률 * factor가 된다.
    - 예를 들어 현재 학습률이 0.01이고 factor가 0.5일 때, 콜백 함수가 실행된다면 그다음 학습률은 0.005가 된다.
- min_lr:
    - 학습률의 하한선을 지정한다.
    - 예를 들어 현재 학습률이 0.1이고 factor가 0.5, min_lr이 0.03이라면 첫 번째로 콜백 함수가 적용될 때 학습률의 하한선 값은 0.03×(0.1×0.5)처럼 계산된다.
- verbose:
    - 조기 종료의 시작과 끝을 출력하기 위해 사용한다.
    - 1로 설정할 경우 조기 종료가 적용되면 적용되었다고 화면에 출력되지만, 0으로 설정할 경우 아무런 출력 없이 학습을 종료한다.

> #### 콜백 함수(callback)
> - 개발자가 명시적으로 함수를 호출하는 것이 아니라 개발자는 단지 함수 등록만 하고 특정 이벤트 발생에 의해 함수를 호출하고 처리하도록 하는 것이 콜백 함수이다.
> - 콜백 함수로는 동기적(synchronous) 함수와 비동기적(asynchronous) 함수가 있다.
> - 동기적 함수는 코드가 위에서 아래로, 왼쪽에서 오른쪽으로 순차적으로 실행되는 함수이며 비동기 함수는 병렬 처리와 같다고 이해하면 된다.
> - 어떤 코드를 실행했을 때 상당한 시간을 기다려야 하는 경우 해당 코드가 완료될 때까지 기다리는 것이 아닌 다른 코드가 먼저 처리되도록 하는 것이 비동기 함수이다.

#### (2)
- 실제로 학습률을 업데이트한다.
- 에포크 단위로 검증 데이터셋에 대한 오차(val_loss)를 받아서 이전 오차와 비교했을 때 차이가 없다면 학습률을 업데이트한다.

---
- 이번에는 조기 종료에 대한 클래스이다.
- 특정 에포크 후에도 오차가 개선되지 않을 때 훈련을 조기 종료한다.
```py
# 8-25 조기 종료

class EarlyStopping():
    def __init__(self, patience=5, verbose=False, delta=0, path='/Users/ramy/PycharmProjects/Pytorch/080289/chap08/data/checkpoint.pt'):
        # (1)
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        # 검증 데이터셋에 대한 오차 최적화 값(오차가 가장 낮은 값)
        self.best_score = None
        # 조기 종료를 의미하며 초깃값은 False로 설정
        self.early_stop = False
        # np.Inf(infinity)는 넘파이에서 무한대를 표현
        self.val_loss_min = np.Inf
        # (2)
        self.delta = delta
        # 모델이 저장될 경로
        self.path = path

    # 에포크만큼 학습이 반복되면서 best_loss가 갱신되고, best_loss에 진전이 없으면 조기 종료한 후 모델을 저장
    def __call__(self, val_loss, model):
        score = -val_loss

        # best_score에 값이 존재하지 않으면 실행
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        # best_score + delta가 score보다 크면 실행
        elif score < self.best_score + self.delta:
            self.counter += 1
            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        # 그 외 모든 경우에 실행
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    # 검증 데이터셋에 대한 오차가 감소하면 모델을 저장
    def save_checkpoint(self, val_loss, model):
        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')
        # 지정된 경로에 모델 저장
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss
```

#### (1)
- patience: 오차 개선이 없다고 바로 종료하지 않고 개선이 없는 에포크를 얼마나 기다려 줄지 지정한다.
- 예제에서는 5라고 지정했기 때문에 개선이 없는 에포크가 다섯 번 지속될 경우 학습을 종료한다.

#### (2)
- delta: 오차가 개선되고 있다고 판단하기 위한 최소 변화량을 나타낸다.
- 변화량이 delta보다 적다면 개선이 없다고 판단한다.
- 일반적으로 케라스에서 제공하는 콜백(keras.callbacks)을 이용하면 손쉽게 조기 종료를 구현할 수 있지만 파이토치에서는 조기 종료 함수 자체를 사용자가 직접 구현해야 한다.
- 이러한 과정이 번거롭다면 케라스를 이용하면 편리하다.
- 케라스의 콜백을 이용하는 방법은 다음과 같다.
```py
from keras.callbacks import ModelCheckpoint, EarlyStopping
# 파일명 지정
checkpoint = ModelCheckpoint('checkpoint-epoch.h5'.format(EPOCH, BATCH_SIZE),
    # val_loss 값이 개선되었을 때 호출
    monitor='val_loss',
    # 로그 출력
    verbose=1,
    # 가장 최적의 값만 저장
    save_best_only=True,
    # auto 의미는 시스템이 알아서 best 값을 찾으라는 것
    mode='auto'
    )

# 학습률 업데이트 기준 설정(val_loss)
earlystopping = EarlyStopping(monitor='val_loss',
    # 에포크가 진행되는 열 번 동안 모델의 오차가 개선되지 않는다면 종료
    patience=10
    )
```

---
- 예제는 학습률 감소와 조기 종료 두 개에 대한 성능 튜닝을 진행하고 있다.
- 즉, 함수에 넘겨주는 인수(argument) 값에 따라 다른 동작을 하도록 해야 하는데, 이때 사용할 수 있는 것이 argparse 라이브러리이다.
- ArgumentParser()를 이용하여 변수와 타입을 정의해 주고 add_argument()를 이용해서 변수에 인수 값을 하나씩 추가한다.
- 그리고 마지막으로 parse_args()를 통해 사용자로부터 입력받은 값들을 args 변수에 저장한다.
```py
# 8-26 인수 값 지정

# 인수 값을 받을 수 있는 인스턴스 생성
parser = argparse.ArgumentParser()
# (1)
parser.add_argument('--lr-scheduler', dest='lr_scheduler', action='store_true')
# 조기 종료 사용 여부
parser.add_argument('--early-stopping', dest='early_stopping', action='store_true')
# (2)
args = parser.parse_args(['--lr-scheduler'])

# 결과 확인
print("lr_scheduler:", args.lr_scheduler)
print("early_stopping:", args.early_stopping)
```

#### (1)
- 원하는 인수 값을 추가한다. 
- 이때 parser.add_argument()는 인수 개수만큼 만들어 준다.

![](./assets/Ch08-2/code06.jpg)

- 사용된 파라미터:
    - 첫 번째 파라미터: 옵션 문자열의 이름으로 명령을 실행할 때 사용한다.
    - dest: 입력 값이 저장되는 변수이다. 예제의 경우 lr_scheduler 변수에 입력 값이 저장된다.
    - action: action을 store_true로 지정하면 입력 값을 dest 파라미터에 의해 생성된 변수에 저장한다.

#### (2)
- 입력받은 인수 값(예 lr_scheduler)이 실제로 args 변수에 저장된다.

---
- 이번 예제에서는 모델의 네트워크를 생성하는 것이 아닌 사전 훈련된 ResNet50을 사용한다.
- ResNet50에서 사용하는 파라미터에 대해 확인해 본다.
- 그 전에 예제 진행을 위해 ipywidgets 라이브러리를 아나콘다 프롬프트에서 설치한다.
```
pip install ipywidgets
```
```py
# 8-27 사전 훈련된 모델의 파라미터 확인

# CPU를 사용하는지 GPU를 사용하는지 검사
print(f"Computation device: {device}\n")
# 사전 훈련된 ResNet50 사용
model = models.resnet50(pretrained=True).to(device)
# 총 파라미터 수
total_params = sum(p.numel() for p in model.parameters())
print(f"{total_params:,} total parameters.")
total_trainable_params = sum(
    # 학습 가능한 파라미터 수
    p.numel() for p in model.parameters() if p.requires_grad)
print(f"{total_trainable_params:,} training parameters.")
```
- 다음은 전체 파라미터와 학습 가능한 파라미터 수이다.
- 책에서는 CPU를 사용했지만 앞에서 GPU가 정상적으로 설치되었다면 ‘Computation device’에서 gpu가 출력될 것이다.
```
Computation device: cpu

25,557,032 total parameters.
25,557,032 training parameters.
```
- 출력 결과 CPU를 사용할 것이며 전체 파라미터와 학습 가능한 파라미터는 25,557,032개라는 것을 보여 준다.
- 초기 학습률, 에포크 및 옵티마이저와 손실 함수를 지정한다.
```py
# 8-28 옵티마이저와 손실 함수 지정

lr = 0.001
epochs = 100
optimizer = optim.Adam(model.parameters(), lr=lr)
criterion = nn.CrossEntropyLoss()
```
- '--lr-scheduler' 또는 '--early-stopping'처럼 어떤 인수도 사용하지 않을 때 오차, 정확도 및 모델의 이름으로 사용할 문자열을 지정한다.
```py
# 8-29 오차, 정확도 및 모델의 이름에 대한 문자열

# 오차 출력에 대한 문자열
loss_plot_name = 'loss'
# 정확도 출력에 대한 문자열
acc_plot_name = 'accuracy'
# 모델을 저장하기 위한 문자열
model_name = 'model'
```
- '--lr-scheduler' 또는 '--early-stopping' 인수를 사용할 경우 오차, 정확도 및 모델의 이름으로 사용할 문자열을 지정한다.
```py

```
- 훈련 데이터셋을 이용한 모델 학습 함수를 정의한다.
```py
# 8-31 모델 학습 함수

def training(model, train_dataloader, train_dataset, optimizer, criterion):
    print('Training')
    model.train()
    train_running_loss = 0.0
    train_running_correct = 0
    counter = 0
    total = 0
    # 훈련 진행 과정을 시각적으로 표현
    prog_bar = tqdm(enumerate(train_dataloader), total=int(len(train_dataset)/train_dataloader.batch_size))

    for i, data in prog_bar:
        counter += 1
        data, target = data[0].to(device), data[1].to(device)
        total += target.size(0)
        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, target)
        train_running_loss += loss.item()
        _, preds = torch.max(outputs.data, 1)
        train_running_correct += (preds == target).sum().item()
        loss.backward()
        optimizer.step()

    train_loss = train_running_loss / counter
    train_accuracy = 100. * train_running_correct / total
    return train_loss, train_accuracy
```
- 다음은 모델 성능을 검증하기 위한 함수이다.
```py
# 8-32 모델 검증 함수

def validate(model, test_dataloader, val_dataset, criterion):
    print('Validating')
    model.eval()
    val_running_loss = 0.0
    val_running_correct = 0
    counter = 0
    total = 0
    # 모델 검증 과정을 시각적으로 표현
    prog_bar = tqdm(enumerate(test_dataloader), total=int(len(val_dataset)/test_dataloader.batch_size))

    with torch.no_grad():
        for i, data in prog_bar:
            counter += 1
            data, target = data[0].to(device), data[1].to(device)
            total += target.size(0)
            outputs = model(data)
            loss = criterion(outputs, target)

            val_running_loss += loss.item()
            _, preds = torch.max(outputs.data, 1)
            val_running_correct += (preds == target).sum().item()

        val_loss = val_running_loss / counter
        val_accuracy = 100. * val_running_correct / total
        return val_loss, val_accuracy
```
- 데이터셋과 모델에 대한 준비가 완료되었다.
- 이제 모델을 학습시켜 본다.
```py
# 8-33 모델 학습

# 훈련 데이터셋을 이용한 모델 학습 결과(오차, 정확도)를 저장하기 위한 변수(리스트 형태를 가짐)
train_loss, train_accuracy = [], []

# 검증 데이터셋을 이용한 모델 성능 결과(오차, 정확도)를 저장하기 위한 변수(리스트 형태를 가짐)
val_loss, val_accuracy = [], []

start = time.time()
for epoch in range(epochs):
    print(f"Epoch {epoch+1} of {epochs}")
    train_epoch_loss, train_epoch_accuracy = training(
        model, train_dataloader, train_dataset, optimizer, criterion
    )
    val_epoch_loss, val_epoch_accuracy = validate(
        model, val_dataloader, val_dataset, criterion
    )
    train_loss.append(train_epoch_loss)
    train_accuracy.append(train_epoch_accuracy)
    val_loss.append(val_epoch_loss)
    val_accuracy.append(val_epoch_accuracy)
    # 인수 값이 lr_scheduler이면 다음을 실행
    if args['lr_scheduler']:
        lr_scheduler(val_epoch_loss)
    # 인수 값이 early_stopping이면 다음을 실행
    if args['early_stopping']:
        early_stopping(val_epoch_loss, model)
        if early_stopping.early_stop:
            break
    print(f"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_accuracy:.2f}")
    print(f'Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f}')
end = time.time()
print(f"Training time: {(end-start)/60:.3f} minutes")
```
- 다음은 모델 학습 결과이다.
```
Epoch 1 of 100
Training
Validating
Train Loss: 2.1123, Train Acc: 60.04
Val Loss: 13.3437, Val Acc: 55.20
Epoch 2 of 100
Training
Validating
Train Loss: 0.5598, Train Acc: 73.90
Val Loss: 0.6033, Val Acc: 68.40
... 중간 생략 ...
Epoch 99 of 100
Training
Validating
Train Loss: 0.0340, Train Acc: 99.20
Val Loss: 1.5805, Val Acc: 68.60
Epoch 100 of 100
Training
Validating
Train Loss: 0.0394, Train Acc: 98.80
Val Loss: 1.0129, Val Acc: 76.00
Training time: 654.208 minutes
```
- CPU를 이용하여 에포크 100을 수행할 경우 약 11시간 정도의 시간이 필요함을 보여준다.
- 따라서 빠른 학습을 원한다면 GPU 환경에서 학습을 진행하는 것이 좋다.
- 여건이 안 되면 코랩에서 GPU로 런타임을 설정하고 실행한다.
- 마지막으로 모델의 정확도와 오차를 그래프를 통해서 확인해 본다.
- 이때 출력 결과는 어떤 인수도 사용되는 않는 모델의 학습 결과이다.
```py
# 코드 8-34 모델 학습 결과 출력

print('Saving loss and accuracy plots...')
plt.figure(figsize=(10, 7))
# 훈련 데이터셋에 대한 오차를 그래프로 출력
plt.plot(train_accuracy, color='green', label='train accuracy')
# 검증 데이터셋에 대한 정확도를 그래프로 출력
plt.plot(val_accuracy, color='blue', label='validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig(f"/Users/ramy/PycharmProjects/Pytorch/080289/chap08/img/{acc_plot_name}.png")
plt.show()
plt.figure(figsize=(10, 7))
# 훈련 데이터셋에 대한 정확도를 그래프로 출력
plt.plot(train_loss, color='orange', label='train loss')
# 검증 데이터셋에 대한 오차를 그래프로 출력
plt.plot(val_loss, color='red', label='validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.savefig(f"/Users/ramy/PycharmProjects/Pytorch/080289/chap08/img/{loss_plot_name}.png")
plt.show()

print('Saving model...')
# 모델을 저장
torch.save(model.state_dict(), f"/Users/ramy/PycharmProjects/Pytorch/080289/chap08/img/{model_name}.pth")
print('TRAINING COMPLETE')
```
- 모델 학습에 대한 출력 결과:

![](./assets/Ch08-2/deeplearning17.jpg)

- 이제 모든 코드가 완료되었다.
- 이렇게 작성된 코드를 파이썬(.py)으로 저장한다.
- 실행 결과를 기존과 다르게 확인하는 이유는 적용해야 할 인자가 두 개이기 때문이다.
- 먼저 어떤 인수도 적용되지 않은 결과를 확인하기 위해 아나콘다 프롬프트에서 다음 명령을 실행한다.
- 이렇게 실행된 결과는 앞에서 실행한 결과와 동일하다.
```
python es-python_8장.py
```
- 다음은 어떤 인수도 적용하지 않았을 때의 실행 결과이다.
```
Computation device: cpu

25,557,032 total parameters.
25,557,032 training parameters.
Epoch 1 of 100
Training
  0%| 
| 0/15 [00:00<?, ?it/s]e:\Anaconda3\envs\pytorch\lib\site-packages\torch\nn\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ..\c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
16it [04:41, 17.62s/it]
Validating
16it [01:30,  5.64s/it]
Train Loss: 2.2272, Train Acc: 58.84
Val Loss: 7.0938, Val Acc: 43.60
Epoch 2 of 100
Training
16it [04:39, 17.45s/it]
Validating
16it [01:30, 5.66s/it]
Train Loss: 0.5848, Train Acc: 71.69
Val Loss: 2.0658, Val Acc: 54.80
Epoch 3 of 100
Training
16it [04:39, 17.44s/it]
Validating
16it [01:30,  5.64s/it]
Train Loss: 0.4854, Train Acc: 76.51
Val Loss: 0.7689, Val Acc: 66.60
... 중간 생략 ...
Epoch 97 of 100
Training
16it [04:41, 17.58s/it]
Validating
16it [01:29,  5.62s/it]
Train Loss: 0.0410, Train Acc: 98.19
Val Loss: 0.8700, Val Acc: 75.20
Epoch 98 of 100
Training
16it [04:40, 17.52s/it]
Validating
16it [01:30,  5.68s/it]
Train Loss: 0.1077, Train Acc: 95.98
Val Loss: 0.9775, Val Acc: 80.60
Epoch 99 of 100
Training
16it [04:44, 17.81s/it]
Validating
16it [01:30,  5.66s/it]
Train Loss: 0.1609, Train Acc: 94.38
Val Loss: 1.9502, Val Acc: 68.40
Epoch 100 of 100
Training
16it [04:43, 17.72s/it]
Validating
16it [01:29,  5.62s/it]
Train Loss: 0.0995, Train Acc: 96.59
Val Loss: 1.5691, Val Acc: 72.00
Training time: 618.836 minutes
Saving loss and accuracy plots...
Saving model...
TRAINING COMPLETE
```
- 에포크를 100으로 지정했기 때문에 상당히 긴 시간의 학습이 진행되었다.
- 다음 그림은 그래프를 이용한 출력 결과이다.

![](./assets/Ch08-2/deeplearning18.jpg)

![](./assets/Ch08-2/deeplearning19.jpg)

- 정확도의 경우 위아래로 많은 변동이 있는 것을 볼 수 있다.
- 정확도가 10% 이상 차이가 나는 일부 에포크 사이는 기복이 매우 심하다.
- 오차에 대한 그래프도 크게 다르지 않다.
- 특히 에포크 10 이후부터 검증 데이터셋에 대한 오차가 미세한 차이로 우상향하는 것을 볼 수 있다.
- 이것은 모델이 과적합되기 시작했으며 적절한 훈련을 계속하려면 학습률 값을 줄여야 한다는 것을 보여 준다.
- 이번에는 학습률 감소에 대한 결과를 확인하기 위해 아나콘다 프롬프트에서 다음 명령을 실행한다.
```
python es-python_8장.py --lr-scheduler
```
- 다음은 학습률 감소와 관련된 인수를 입력했을 때의 결과이다.
```
Computation device: cpu

25,557,032 total parameters.
25,557,032 training parameters.
INFO: Initializing learning rate scheduler
Epoch 1 of 100
Training
  0%| 
| 0/15 [00:00<?, ?it/s]C:\Users\Metanet\AppData\Roaming\Python\Python38\site-packages\torch\nn\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ..\c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
16it [09:02, 33.91s/it]
Validating
16it [02:08,  8.06s/it]
Train Loss: 2.1396, Train Acc: 61.04
Val Loss: 6.2706, Val Acc: 37.80
Epoch 2 of 100
Training
16it [05:41, 21.32s/it]
Validating
16it [01:16,  4.80s/it]
Train Loss: 0.5996, Train Acc: 69.68
Val Loss: 1.3892, Val Acc: 51.20
Epoch 3 of 100
Training
16it [04:17, 16.11s/it]
Validating
16it [01:15,  4.75s/it]
Train Loss: 0.5297, Train Acc: 74.50
Val Loss: 0.7101, Val Acc: 67.00
... 중간 생략 ...
Epoch 97 of 100
Training
16it [03:58, 14.91s/it]
Validating
16it [01:16,  4.78s/it]
Train Loss: 0.0017, Train Acc: 100.00
Val Loss: 0.5876, Val Acc: 83.40
Epoch 98 of 100
Training
16it [04:02, 15.13s/it]
Validating
16it [01:16,  4.78s/it]
Train Loss: 0.0017, Train Acc: 100.00
Val Loss: 0.5880, Val Acc: 84.00
Epoch 99 of 100
Training
16it [04:01, 15.08s/it]
Validating
16it [01:14,  4.69s/it]
Train Loss: 0.0019, Train Acc: 100.00
Val Loss: 0.5919, Val Acc: 83.80
Epoch 100 of 100
Training
16it [03:59, 14.94s/it]
Validating
16it [01:14,  4.64s/it]
Train Loss: 0.0023, Train Acc: 100.00
Val Loss: 0.5959, Val Acc: 83.60
Training time: 589.638 minutes
Saving loss and accuracy plots...
Saving model...
TRAINING COMPLETE
```
- 역시 100으로 지정된 에포크 모두 수행되기 때문에 상당히 긴 시간이 필요하다.
- 그 결과를 그래프로 확인해 본다.

![](./assets/Ch08-2/deeplearning20.jpg)

![](./assets/Ch08-2/deeplearning21.jpg)

- 정확도를 보여 주는 그래프가 앞에서 살펴보았던 그래프와는 다르게 완만한 곡선 형태를 보여 준다.
- 또한, 훈련이 종료된 시점의 검증 데이터셋에 대한 정확도도 높게 나타나고 있다.
- 그리고 오차 그래프의 경우 그래프가 우상향하는 현상도 없어졌다.
- 즉, 학습률 스케줄러가 성능 향상에 어느 정도 기여했음을 의미한다.
- 그러나 자세히 관찰하면 검증 데이터셋에 대한 오차가 에포크 20 정도에서도 정체되기 시작한다.
- 즉, 에포크를 30 정도만 수행해도 모델 훈련에 여전히 좋은 결과를 얻을 수 있을 것이라고 추측할 수 있다.
- 마지막으로 조기 종료에 대한 결과를 살펴본다.
- 다음 명령을 아나콘다 프롬프트에서 실행한다.
```
python es-python_8장.py --early-stopping
```
- 조기 종료 인수를 적용했을 때의 결과는 다음과 같다.
```
Computation device: cpu

25,557,032 total parameters.
25,557,032 training parameters.
INFO: Initializing early stopping
Epoch 1 of 100
Training
  0%| 
| 0/15 [00:00<?, ?it/s]e:\Anaconda3\envs\pytorch\lib\site-packages\torch\nn\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ..\c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
16it [04:45, 17.84s/it]
Validating
16it [01:34,  5.91s/it]
Train Loss: 2.1789, Train Acc: 58.23
Val Loss: 64.6766, Val Acc: 14.60
Epoch 2 of 100
Training
16it [04:31, 16.94s/it]
Validating
16it [01:29,  5.60s/it]
Train Loss: 0.6728, Train Acc: 65.66
Val Loss: 1.6799, Val Acc: 64.60
Epoch 3 of 100
Training
16it [04:33, 17.09s/it]
Validating
16it [01:31,  5.74s/it]
Train Loss: 0.5560, Train Acc: 70.28
Val Loss: 0.5631, Val Acc: 71.40
Epoch 4 of 100
Training
16it [04:46, 17.90s/it]
Validating
16it [01:34,  5.93s/it]
Train Loss: 0.5004, Train Acc: 79.92
Val Loss: 0.5125, Val Acc: 77.40
Epoch 5 of 100
Training
16it [04:47, 17.94s/it]
Validating
16it [01:34,  5.90s/it]
EarlyStopping counter: 1 out of 5
Train Loss: 0.3710, Train Acc: 83.53
Val Loss: 0.6830, Val Acc: 72.20
Epoch 6 of 100
Training
16it [04:46, 17.94s/it]
Validating
16it [01:34,  5.90s/it]
EarlyStopping counter: 2 out of 5
Train Loss: 0.4656, Train Acc: 78.11
Val Loss: 0.7071, Val Acc: 70.40
Epoch 7 of 100
Training
16it [04:36, 17.26s/it]
Validating
16it [01:30,  5.66s/it]
EarlyStopping counter: 3 out of 5
Train Loss: 0.4010, Train Acc: 83.33
Val Loss: 0.5996, Val Acc: 74.80
Epoch 8 of 100
Training
16it [04:34, 17.17s/it]
Validating
16it [01:30,  5.68s/it]
EarlyStopping counter: 4 out of 5
Train Loss: 0.3679, Train Acc: 83.94
Val Loss: 1.4061, Val Acc: 58.00
Epoch 9 of 100
Training
16it [04:34, 17.14s/it]
Validating
16it [01:30,  5.68s/it]
EarlyStopping counter: 5 out of 5
Training time: 55.807 minutes
Saving model...
TRAINING COMPLETE
```
- 다섯 번째 에포크부터 조기 종료가 수행되고 있다.
- 그 결과를 그래프로 확인해 본다.
- 조기 종료로 인해 실제로 학습을 종료할 때까지 기다려 주는 파라미터인 patience를 5로 설정했기 때문에 빠른 종료가 이루어졌지만 좀 더 길게 설정하면서 다양한 학습 방법을 익혀 보기 바란다(실제로 5로 설정하는 것은 너무 성급한 판단일 수도 있기 때문에 더 긴 에포크로 설정해서 테스트를 진행해 보아야 한다).

![](./assets/Ch08-2/deeplearning22.jpg)

![](./assets/Ch08-2/deeplearning23.jpg)

- 다섯 번째 에포크부터 조기 종료가 수행되고 있기 때문에 실제로 학습은 네 번째 에포크까지만 수행되었다고 할 수 있다(데이터셋은 랜덤으로 가져오기 때문에 결과가 책과 다를 수 있다).
- 명심해야 할 것은 조기 종료가 항상 성능에 좋은 영향을 미치는 것은 아니다.
- 조기 종료로 인해 모델이 제대로 학습하지 못할 수 있다.
- 실제로 검증 데이터셋에 대한 정확도 그래프가 위아래로 오가면서 불안정한 결과를 출력하고 있다.
- 그렇다고 학습을 계속 이어 간다고 해서 더 좋은 결과를 얻을 수 있다는 보장도 없다.
- 따라서 그래프가 의미하는 내용을 잘 이해하고 적절한 성능 향상 방안을 적용하는 것이 중요하다.
- 앞에서 검증 데이터셋에 대한 정확도는 좋지 않지만, 오차는 많이 낮아진 것을 확인할 수 있다.
- 따라서 정확도만 보고 조기 종료가 효과가 없다고 판단하기에는 숲이 아닌 나무만 보고 판단한 결과와 같다.
- 분명한 것은 학습률 스케줄러를 이용한 학습률 조정 기법과 조기 종료가 모델 성능을 향상시키는 데는 도움이 된다는 것이다(조기 종료의 경우에는 성능 향상보다는 자원(CPU/메모리)의 효율화라고 보는 것이 정확하다).
- 단 모든 모델에 일괄적으로 적용하는 것이 아닌, 기존의 출력된 그래프를 해석해서 어떤 성능 기법을 적용할지 결정하는 것이 중요하다.
