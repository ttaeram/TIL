# Chapter 06: 합성곱 신경망 2
## 01. 이미지 분류를 위한 신경망
### 1-1. LeNet-5
- LeNet-5는 합성곱 신경망이라는 개념을 최초로 얀 르쿤(Yann LeCun)이 개발한 구조이다.
- 1995년 얀 르쿤, 레옹 보토(Leon Bottu), 요슈아 벤지오(Yosua Bengio), 패트릭 하프너(Patrick Haffner)가 수표에 쓴 손글씨 숫자를 인식하는 딥러닝 구조 LeNet-5를 발표했는데, 그것이 현재 CNN의 초석이 되었다.
- LeNet-5는 합성곱(convolutional)과 다운 샘플링(sub-sampling)(혹은 풀링)을 반복적으로 거치면서 마지막에 완전연결층에서 분류를 수행한다.
- 다음 그림을 이용하여 구체적으로 살펴보면 C1에서 5×5 합성곱 연산 후 28×28 크기의 특성 맵(feature map) 여섯 개를 생성한다.
- S2에서 다운 샘플링하여 특성 맵 크기를 14×14로 줄인다.
- 다시 C3에서 5×5 합성곱 연산하여 10×10 크기의 특성 맵 16개를 생성하고, S4에서 다운 샘플링하여 특성 맵 크기를 5×5로 줄인다.
- C5에서 5×5 합성곱 연산하여 1×1 크기의 특성 맵 120개를 생성하고, 마지막으로 F6에서 완전연결층으로 C5의 결과를 유닛(unit)(또는 노드) 84개에 연결시킨다.
- 이때 C로 시작하는 것은 합성곱층을 의미하고, S로 시작하는 것은 풀링층을 의미하며, F로 시작하는 것은 완전연결층을 의미한다.

![](./assets/Ch06/Deeplearning01.jpg)

- LeNet-5를 사용하는 예제를 구현한다.
- 개와 고양이 데이터셋을 사용한다.
- 구현할 신경망:

![](./assets/Ch06/Deeplearning02.jpg)

- 32×32 크기의 이미지에 합성곱층과 최대 풀링층이 쌍으로 두 번 적용된 후 완전연결층을 거쳐 이미지가 분류되는 신경망이다.
- 신경망에 대한 설명:

|계층 유형|특성 맵|크기|커널 크기|스트라이드|활성화 함수|
|:---:|:---:|:---:|:---:|:---:|:---:|
|이미지|1|32x32|-|-|-|
|합성곱층|6|28x28|5x5|1|렐루(ReLU)|
|최대 풀링층|6|14x14|2x2|2|-|
|합성곱층|16|10x10|5x5|1|렐루(ReLU)|
|최대 풀링층|16|5x5|2x2|2|-|
|완전 연결층|-|120|-|-|렐루(ReLU)|
|완전 연결층|-|84|-|-|렐루(ReLU)|
|완전 연결층|-|2|-|-|소프트맥스(softmax)|