# Chapter 04: ë­ì²´ì¸ ìµìˆ™í•´ì§€ê¸°
- ë­ì²´ì¸ì€ LLMì„ í™œìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“ˆì˜ ëª¨ìŒì´ì ì¡°í•©ì´ë‹¤.

## 01. ë­ì²´ì¸ í›‘ì–´ë³´ê¸°
- ë­ì²´ì¸ì€ LLM ì—´í’ì´ ì¼ì–´ë‚˜ê¸° ì‹œì‘í•œ ì‹œì ì— ë­ì²´ì¸ì„ ì²˜ìŒ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì„ ë³´ì˜€ìœ¼ë©° ì´í›„ ì»¤ë®¤ë‹ˆí‹° êµ¬ì„±ì›ë“¤ì— ì˜í•´ ë”ìš± ë°œì „í•˜ê²Œ ë˜ì—ˆë‹¤.

![](./assets/Ch04/LLM01.jpg)

- ì•µë¬´ìƒˆëŠ” ì–¸ì–´ ëª¨ë¸ì„ ìƒì§•ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ë‹¤.
- ì•µë¬´ìƒˆê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ë”°ë¼ì„œ ë§í•  ìˆ˜ ìˆë‹¤ëŠ” ì  ë•Œë¬¸ì— ë­ì²´ì¸ì˜ ìƒì§•ì²˜ëŸ¼ í‘œí˜„ëœ ê²ƒì´ë‹¤.
- 3ì¥ì—ì„œ RAGë¥¼ êµ¬í˜„í•˜ë ¤ë©´ ì •ë³´ ê²€ìƒ‰ê³¼ í…ìŠ¤íŠ¸ ìƒì„±ì´ í•„ìš”í•˜ë‹¤ê³  í–ˆëŠ”ë°, ì—¬ê¸°ì„œ í…ìŠ¤íŠ¸ ìƒì„±ì€ LLMì˜ ëª«ì´ê³  ìš°ë¦¬ê°€ ì‹ ê²½ì“¸ ê²ƒì€ ì •ë³´ ê²€ìƒ‰ì´ë‹¤.
- ì •ë³´ ê²€ìƒ‰ì€ ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì•„ë‹Œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì„ë² ë”© ê³¼ì •ì´ í•„ìš”í•˜ê³ , ì´í›„ ìœ ì‚¬ë„ ê²€ìƒ‰ê³¼ ë­í‚¹ ì²˜ë¦¬ê°€ í•„ìš”í•˜ë‹¤.
- ì •ë¦¬í•˜ë©´ ìš°ë¦¬ê°€ í•´ì•¼ í•  ì¼ì€ ì„ë² ë”©, ìœ ì‚¬ë„ ê²€ìƒ‰, ë­í‚¹ ì²˜ë¦¬ì¸ë° ì´ ëª¨ë“  ê²ƒì´ ë­ì²´ì¸ìœ¼ë¡œ ê°€ëŠ¥í•˜ë‹¤.

![](./assets/Ch04/LLM02.png)

## 02. ë­ì²´ì¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í™˜ê²½ êµ¬ì„±
- ë­ì²´ì¸ì€ íŒŒì´ì¬ê³¼ ìë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§€ì›í•œë‹¤.
- íŒŒì´ì¬ì„ ì´ìš©í•´ ì½›ë¸Œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì€ í¬ê²Œ ë‘ ê°€ì§€ê°€ ìˆë‹¤.
  - ì»´í“¨í„°ì— ì•„ë‚˜ì½˜ë‹¤ë¥¼ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•
  - êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” ì½”ë©ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
- LLMê³¼ ë­ì²´ì¸ìœ¼ë¡œ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì›¹í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ê¸° ìœ„í•´ ìŠ¤íŠ¸ë¦¼ë¦¿ì„ ì‚¬ìš©í•  í…ë°, ì´ê²ƒì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì»´í“¨í„°ì— ì•„ë‚˜ì½˜ë‹¤ë¥¼ ì„¤ì¹˜í•´ì•¼ í•œë‹¤.

### 2-1. ì•„ë‚˜ì½˜ë‹¤ í™˜ê²½ êµ¬ì„±
#### (1) ì•„ë‚˜ì½˜ë‹¤ ì„¤ì¹˜í•˜ê¸°
1. [ì•„ë‚˜ì½˜ë‹¤ ì‚¬ì´íŠ¸](https://www.anaconda.com/download#)ì—ì„œ ì•„ë‚˜ì½˜ë‹¤ë¥¼ ë‚´ë ¤ë°›ëŠ”ë‹¤.
  - ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì»´í“¨í„°ì— ë§ëŠ” ë²„ì „ì„ ë‚´ë ¤ë°›ìœ¼ë©´ ëœë‹¤.
2. ë‚´ë ¤ë°›ì€ ì„¤ì¹˜ íŒŒì¼ì„ ì‹¤í–‰í•˜ë©´ ì„¤ì¹˜ í™”ë©´ì´ ë‚˜ì˜¨ë‹¤.
3. ë¼ì´ì„ ìŠ¤ ë™ì˜ í™”ë©´ì´ ë‚˜ì˜¤ë©´ `I Agree`ë¥¼ í´ë¦­í•œë‹¤.
4. ì„¤ì¹˜ ìœ í˜• ì„ íƒ í™”ë©´ì´ ë‚˜ì˜¤ë©´ `Just me`ë¥¼ ì„ íƒí•˜ê³  ë„˜ì–´ê°„ë‹¤.
5. ì„¤ì¹˜ ê²½ë¡œë¥¼ ì„ íƒí•˜ëŠ” í™”ë©´ì´ ë‚˜ì˜¤ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë‘ê³  ë„˜ì–´ê°„ë‹¤.
6. ì„¤ì¹˜ ì‹œì‘ í™”ë©´ì´ ë‚˜ì˜¤ë©´ `Add Anoconda3 to my PATH environment variable`ì„ ì²´í¬í•œë‹¤. ì´ëŠ” ì•„ë‚˜ì½˜ë‹¤ì˜ í™˜ê²½ ë³€ìˆ˜ ìë™ ë“±ë¡ ì—¬ë¶€ì´ë‹¤.
7. ì„¤ì¹˜ê°€ ì‹œì‘ëœë‹¤.
8. ì„¤ì¹˜ ì¢…ë£Œ í›„ ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì‚¬ìš© ì¤€ë¹„ ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.
9. ì„¤ì¹˜ ì¢…ë£Œ í›„ ìœˆë„ìš° íƒìƒ‰ê¸°ì—ì„œ ë‚´ PC ìš°í´ë¦­ í›„ `ì†ì„± > ê³ ê¸‰ ì‹œìŠ¤í…œ ì„¤ì • > í™˜ê²½ ë³€ìˆ˜`ë¥¼ ì„ íƒí•œë‹¤.
  - ì´í›„ `ì‚¬ìš©ì ë³€ìˆ˜`ì—ì„œ `Path`ë¥¼ ì„ íƒí•˜ê³  í¸ì§‘ì„ í´ë¦­í•˜ë©´ ì•„ë‚˜ì½˜ë‹¤ì™€ ê´€ë ¨ëœ í™˜ê²½ ë³€ìˆ˜ê°€ ìƒì„±ë˜ì–´ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

#### (2) ê°€ìƒ í™˜ê²½ ìƒì„±
- ì•„ë‚˜ì½˜ë‹¤ê°€ ì„¤ì¹˜ë˜ì—ˆë‹¤ë©´ ê°€ìƒ í™˜ê²½ì„ êµ¬ì„±í•´ë³¸ë‹¤.
1. ìœˆë„ìš° ì‹œì‘ í™”ë©´ì—ì„œ `Anaconda3 > Anaconda Prompt`ë¥¼ ì„ íƒí•œë‹¤.
2. `conda create -n í™˜ê²½ ì´ë¦„ python=3.8` ëª…ë ¹ì„ í†µí•´ ê°€ìƒ í™˜ê²½ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.
  - ë‹¤ìŒê³¼ ê°™ì´ ì…ë ¥í•˜ì—¬ 'llm'ì´ë¼ëŠ” ì´ë¦„ì˜ ê°€ìƒ í™˜ê²½ì„ ë§Œë“ ë‹¤.
  - íŒŒì´ì¬ 3.8ì„ ì„ íƒí•˜ê³ , ì¤‘ê°„ì— ì„¤ì¹˜ ì—¬ë¶€ëŠ” 'y'ë¥¼ ì…ë ¥í•œë‹¤.
  - `conda create -n llm python=3.8`
3. ìƒì„±ëœ ê°€ìƒ í™˜ê²½ì„ í™•ì¸í•œë‹¤.
  - ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì•„ë‚˜ì½˜ë‹¤ì˜ ê°€ìƒ í™˜ê²½ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
> conda env list

# conda environments:
#
base                 * C:\Users\ryuta\anaconda3
llm                    C:\Users\ryuta\anaconda3\envs\llm
```
4. llm ê°€ìƒ í™˜ê²½ì´ ë§Œë“¤ì–´ì¡Œìœ¼ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ê°€ìƒ í™˜ê²½ì„ í™œì„±í™” í•œë‹¤.
```
>  activate llm
```
  - ê°€ìƒ í™˜ê²½ì„ ì‚­ì œí•˜ê³  ì‹¶ì„ ë•ŒëŠ” ì•„ë˜ ëª…ë ¹ìœ¼ë¡œ ì‚­ì œ ê°€ëŠ¥í•˜ë‹¤.
```
> conda env remove -n llm
```
5. ìƒì„±ëœ ê°€ìƒ í™˜ê²½ì— ì£¼í”¼í„° ë…¸íŠ¸ë¶ì„ ì„¤ì¹˜í•œë‹¤.
  - ë‹¤ìŒ ëª…ë ¹ì€ `activate llm` ì´í›„ì— ì‹¤í–‰í•œë‹¤.
```
> pip install ipykernel
```
  - ê°€ìƒ í™˜ê²½ì— ì»¤ë„ì„ ì—°ê²°í•˜ê¸° ìœ„í•´ ë‹¤ìŒì„ ì‹¤í–‰í•œë‹¤.
```
> python -m ipykernel install --user --name llm --display-name "llm"
```
6. ì„¤ì¹˜ê°€ ëë‚¬ìœ¼ë‹ˆ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì— ì ‘ì†í•´ë³¸ë‹¤.
```
> jupyter notebook
```
7. ì›¹ë¸Œë¼ìš°ì €ì— ì£¼í”¼í„° ë…¸íŠ¸ë¶ì´ ì‹¤í–‰ëœë‹¤.
8. ì˜¤ë¥¸ìª½ `New` ë©”ë‰´ì—ì„œ `llm`ì„ í´ë¦­í•œë‹¤.
9. í•´ë‹¹ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ ì˜ˆì œë¥¼ ì§„í–‰í•˜ë©´ ëœë‹¤.
10. ì‹¤í–‰ì€ `> Run` ë²„íŠ¼ì´ë‚˜ `Shift + Enter` í‚¤ë¥¼ ì‚¬ìš©í•œë‹¤.
11. ì±…ì—ì„œ ì œê³µí•œ ì†ŒìŠ¤ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ê²½ìš°ì—ëŠ” ë‚´ë ¤ë°›ì€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì‚¬ìš©í•œë‹¤.
  - ìš°ì„  ì•„ë˜ URLì—ì„œ ì†ŒìŠ¤ ì½”ë“œë¥¼ ë‚´ë ¤ë°›ëŠ”ë‹¤.
  - https://github.com/gilbutITbook/080413
  - ì´ë²ˆì—ëŠ” `Upload`ë¥¼ í´ë¦­í•œ í›„ ë‚´ë ¤ë°›ì€ ì†ŒìŠ¤ ì½”ë“œë¥¼ ì„ íƒí•œë‹¤.
12. ì†ŒìŠ¤ ì½”ë“œë¥¼ ë¶ˆëŸ¬ì™”ë‹¤ë©´ íŒŒì¼ ì˜†ì— ìˆëŠ” `Upload` ë²„íŠ¼ì„ í´ë¦­í•œë‹¤.
13. ê·¸ëŸ¼ ëª©ë¡ì— ì—…ë¡œë“œí•´ë‘” íŒŒì¼ì´ ë³´ì¸ë‹¤.
  - í•´ë‹¹ íŒŒì¼ì„ í´ë¦­í•˜ë©´ ì½”ë“œê°€ ë³´ì´ëŠ”ë° `> Run` ë²„íŠ¼ìœ¼ë¡œ í•œ ì¤„ ì”© ì‹¤í–‰ì‹œí‚¨ë‹¤.

### 2-2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
#### (1) ë­ì²´ì¸
1. ì•„ë‚˜ì½˜ë‹¤ì˜ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì— ì ‘ì†í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ ë­ì²´ì¸ì„ ì„¤ì¹˜í•œë‹¤.
  - ë²„ì „: 0.0.350
```py
!pip install langchain==0.0.350
```
- ì„¤ì¹˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤.
```
Collecting langchain==0.0.350
  Downloading langchain-0.0.350-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: PyYAML>=5.3 in c:\users\ryuta\anaconda3\envs\llm\lib\site-packages (from langchain==0.0.350) (6.0.2)
Collecting SQLAlchemy<3,>=1.4 (from langchain==0.0.350)
  Downloading sqlalchemy-2.0.41-cp38-cp38-win_amd64.whl.metadata (9.8 kB)
Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.0.350)
...ì¤‘ëµ...
Successfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.4.4 aiohttp-3.10.11 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.0.350 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.22.0 multidict-6.1.0 mypy-extensions-1.1.0 packaging-23.2 propcache-0.2.0 pydantic-2.10.6 pydantic-core-2.27.2 tenacity-8.5.0 typing-extensions-4.13.2 typing-inspect-0.9.0 yarl-1.15.2
```
> - ë­ì²´ì¸ì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ ì•„ë˜ ë°©ë²•ìœ¼ë¡œ ì„¤ì¹˜ëœ ë²„ì „ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
> ```py
> import langchain
> 
> print('The version of langchain is {}'.format(langchain.__version__))
> ```
> - ì‹¤í–‰ ê²°ê³¼:
> ```
> The version of langchain is 0.0.350
> ```
> - ë²„ì „ì´ ë‹¤ë¥´ë‹¤ë©´ ë²„ì „ì„ ì§€ì •í•œ ì„¤ì¹˜ ì½”ë“œë¥¼ í•œ ë²ˆ ë” ì‹¤í–‰ì‹œì¼œì£¼ë©´ ëœë‹¤.

2. ë‹¤ìŒìœ¼ë¡œ openai ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤.
  - ì•„ë˜ ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜í•œë‹¤.
```py
!pip install openai==1.4.0
```

3. ë­ì²´ì¸ê³¼ ìœ ì‚¬í•˜ê²Œ ë‹¤ì–‘í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
Collecting openai==1.4.0
  Downloading openai-1.4.0-py3-none-any.whl.metadata (17 kB)
Requirement already satisfied: anyio<5,>=3.5.0 in c:\users\ryuta\anaconda3\envs\llm\lib\site-packages (from openai==1.4.0) (4.2.0)
Collecting distro<2,>=1.7.0 (from openai==1.4.0)
  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)
...ì¤‘ëµ...
Requirement already satisfied: colorama in c:\users\ryuta\anaconda3\envs\llm\lib\site-packages (from tqdm>4->openai==1.4.0) (0.4.6)
Downloading openai-1.4.0-py3-none-any.whl (221 kB)
Downloading distro-1.9.0-py3-none-any.whl (20 kB)
Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
Installing collected packages: tqdm, distro, openai
Successfully installed distro-1.9.0 openai-1.4.0 tqdm-4.67.1
```

4. ë‹¤ìŒìœ¼ë¡œ í—ˆê¹…í˜ì´ìŠ¤ì˜ LLMì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤.
  - í—ˆê¹…í˜ì´ìŠ¤(Hugging Face)ëŠ” ì¸ê³µì§€ëŠ¥ ì—°êµ¬ ë° ê°œë°œì„ ìœ„í•œ ë„êµ¬, íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì— ì´ˆì ì„ ë§ì¶˜ íšŒì‚¬ë¡œ, ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ê³¼ ì´ë¥¼ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” API, ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì œê³µí•œë‹¤.
  - ì•„ë˜ ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜í•œë‹¤.
```py
!pip install huggingface-hub==0.19.4
```
```
Collecting huggingface-hub==0.19.4
  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)
Collecting filelock (from huggingface-hub==0.19.4)
  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec>=2023.5.0 (from huggingface-hub==0.19.4)
  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)
...ì¤‘ëµ...
Requirement already satisfied: certifi>=2017.4.17 in c:\users\ryuta\anaconda3\envs\llm\lib\site-packages (from requests->huggingface-hub==0.19.4) (2024.8.30)
Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)
Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)
Downloading filelock-3.16.1-py3-none-any.whl (16 kB)
Installing collected packages: fsspec, filelock, huggingface-hub
Successfully installed filelock-3.16.1 fsspec-2025.3.0 huggingface-hub-0.19.4
```

### 2-3. í‚¤ ë°œê¸‰
- LLM APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” í•´ë‹¹ LLMì— ëŒ€í•œ í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ì•¼ í•œë‹¤.
- ì˜ˆì œì— í•„ìš”í•œ ì˜¤í”ˆAIì™€ í—ˆê¹…í˜ì´ìŠ¤ í‚¤ë¥¼ ë°œê¸‰ë°›ëŠ”ë‹¤.

#### (1) ì˜¤í”ˆAI API í‚¤ ë°œê¸‰
- ë¨¼ì € ì˜¤í”ˆAI í‚¤ë¥¼ ë°œê¸‰ë°›ëŠ”ë‹¤.

1. [ì˜¤í”ˆAI ì›¹ì‚¬ì´íŠ¸](https://openai.com/)ì— ì ‘ì†í•œë‹¤.
- ì˜¤ë¥¸ìª½ ìƒë‹¨ì— `Log in / Sign up` ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¡œê·¸ì¸í•œë‹¤.

2. ë¡œê·¸ì¸ í›„, ë©”ë‰´ ì¤‘ ìë¬¼ì‡  ê·¸ë¦¼ì˜ `API Keys`ë¥¼ í´ë¦­í•œë‹¤.
3. `Create new secret key`ë¥¼ í´ë¦­í•œë‹¤.
4. í‚¤ ì´ë¦„ì„ ì…ë ¥ í›„ `Create secret key` ë²„íŠ¼ì„ í´ë¦­í•œë‹¤.
5. ìƒì„±ëœ í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ ë‹¤ë¥¸ ê³³ì— ì €ì¥í•œ í›„ `Done`ì„ í´ë¦­í•œë‹¤.
6. íŒŒì´ì¬ ì½”ë“œì—ì„œ ìƒì„±ëœ í‚¤ë¥¼ ì…ë ¥í•œë‹¤.
```py
import os
os.environ["OPENAI_API_KEY"] = "secret_key"
```

#### (2) í—ˆê¹…í˜ì´ìŠ¤ LLM ì‚¬ìš© í‚¤
- í—ˆê¹…í˜ì´ìŠ¤ì˜ LLM í‚¤ë¥¼ ë°›ì•„ë³´ì.
- ì–¸ì–´ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ì¸¡ë©´ì—ì„œ í—ˆê¹…í˜ì´ìŠ¤ëŠ” ì˜¤í”ˆAIì™€ ìœ ì‚¬í•˜ì§€ë§Œ ëª¨ë¸ì„ ì œê³µí•˜ëŠ” ë°©ì‹ì—ì„œ ì°¨ì´ê°€ ìˆë‹¤.
- ì˜¤í”ˆAIì˜ ê²½ìš° LLM ëª¨ë¸ì„ ìƒì—…ì ìœ¼ë¡œ ë°°í¬í•˜ëŠ” ë°˜ë©´, í—ˆê¹…í˜ì´ìŠ¤ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒíƒœê³„ë¥¼ ì¡°ì„±í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆë‹¤.

1. [í—ˆê¹…í˜ì´ìŠ¤ ì›¹ì‚¬ì´íŠ¸](https://huggingface.co/settings/tokens)ì— ì ‘ì†í•œë‹¤.
  - í—ˆê¹…í˜ì´ìŠ¤ ê³„ì • ìƒì„± í›„ ë¡œê·¸ì¸í•œë‹¤.
2. í† í°ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ë²„íŠ¼ì´ í™œì„±í™”ë˜ì–´ ìˆë‹¤.
  - `New token` ë²„íŠ¼ì„ í´ë¦­í•œë‹¤.
3. `Name`ì— í† í° ì´ë¦„ì„ ì…ë ¥í•œ í›„ `Generate token` ë²„íŠ¼ì„ í´ë¦­í•œë‹¤.
4. ìƒì„±ëœ í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ ë‹¤ë¥¸ ê³³ì— ì €ì¥í•œë‹¤.
5. ì•„ë‚˜ì½˜ë‹¤ì—ì„œ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•œë‹¤.
```py
import os

os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'secret_key'
```

## 03. ë­ì²´ì¸ ì£¼ìš” ëª¨ë“ˆ
- ë­ì²´ì¸ì˜ ëª¨ë“ˆë“¤ì€ ì•„ë˜ì™€ ê°™ë‹¤.
  - ëª¨ë¸ I/O
  - ë°ì´í„° ì—°ê²°
  - ì²´ì¸
  - ë©”ëª¨ë¦¬
  - ì—ì´ì „íŠ¸/íˆ´

### 3-1. ëª¨ë¸ I/O
- ëª¨ë¸ I/OëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©ì„ ìœ„í•œ ëª¨ë“ˆì´ë‹¤.
- LLMê³¼ ìƒí˜¸ ì‘ìš©í•œë‹¤ëŠ” ê²ƒì€ ì•„ë˜ì˜ ì‘ì—…ë“¤ì„ ì˜ë¯¸í•œë‹¤.
  - LLMì— ì „ë‹¬ë  í”„ë¡¬í”„íŠ¸ ìƒì„±
  - ë‹µë³€ì„ ë°›ê¸° ìœ„í•´ ëª¨ë¸ API í˜¸ì¶œ
  - ë‹µë³€ì— ëŒ€í•œ ì¶œë ¥
- ëª¨ë¸ I/OëŠ” LLMê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•´ ì…ë ¥ê³¼ ì¶œë ¥ë¿ë§Œ ì•„ë‹ˆë¼ LLM API í˜¸ì¶œë„ ë‹´ë‹¹í•˜ê¸° ë•Œë¬¸ì— ì•„ë˜ì˜ êµ¬ì„± ìš”ì†Œë¡œ ì´ë¤„ì ¸ ìˆë‹¤.
  - í”„ë¡¬í”„íŠ¸ -> ëª¨ë¸ -> ì¶œë ¥ íŒŒì„œ
- í”„ë¡¬í”„íŠ¸ëŠ” ì…ë ¥ ë°ì´í„°ì™€ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ ê²ƒì„ ì˜ë¯¸í•˜ë©°, ì–¸ì–´ ëª¨ë¸ì€ LLMì„ í¬í•¨í•˜ì—¬ ì±„íŒ… ëª¨ë¸, ì„ë² ë”© ëª¨ë¸ì— ëŒ€í•œ API í˜¸ì¶œ ì—­í• ì„ ë‹´ë‹¹í•œë‹¤.
- LLMì€ ì¼ë°˜ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ëŠ”ë°, ë³´ë‹¤ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì–»ê³  ì‹¶ì„ ë•Œ ì¶œë ¥ íŒŒì„œ(Output Parsers)ë¥¼ ì´ìš©í•œë‹¤.
- ì¶œë ¥ íŒŒì„œëŠ” ëª¨ë¸ì— ì¶œë ¥ í˜•ì‹ì„ ì•Œë ¤ì£¼ê³  ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ë˜ë„ë¡ íŒŒì‹±í•˜ëŠ” ê²ƒì„ ë‹´ë‹¹í•œë‹¤.

> - íŒŒì‹±ì€ ì»´í“¨í„°ê°€ ì“°ì—¬ì§„ ì½”ë“œë‚˜ ë°ì´í„°ë¥¼ ì½ê³  ì´í•´í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.
> - ì˜ˆë¥¼ ë“¤ì–´ ì»´í“¨í„°ê°€ ì›¹ì‚¬ì´íŠ¸ì˜ HTML ì½”ë“œë¥¼ ì½ì„ ë•Œ íŒŒì„œëŠ” ê·¸ ì½”ë“œë¥¼ í•˜ë‚˜í•˜ë‚˜ ì‚´í´ë³´ë©° ì•Œë ¤ì£¼ëŠ” ê²ƒì´ë‹¤.

#### íŒŒì´ì¬ì—ì„œ ì‹¤í–‰í•´ë³´ê¸°
- ì•„ë‚˜ì½˜ë‹¤ì—ì„œ ì•„ë˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤.
- í•œì¤„ì”© ì‹¤í–‰í•´ì•¼ í•œë‹¤.
```py
!pip install langchain==0.0.350
!pip install openai==0.28.1
!pip install huggingface-hub==0.19.4
```

#### í”„ë¡¬í”„íŠ¸ ìƒì„±
- í”„ë¡¬í”„íŠ¸ ìƒì„±ì„ ìœ„í•´ `PromptTemplate`ì„ ì‚¬ìš©í•œë‹¤.
- ì´ëŠ” LLMì— ë¬¸ì¥ì„ ì „ë‹¬í•˜ê¸° ì „ì— ë¬¸ì¥ êµ¬ì„±ì„ í¸ë¦¬í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.
- ì•„ë˜ëŠ” product ë§Œ ë°”ë€Œê³  ë‚˜ë¨¸ì§€ ë¬¸êµ¬ëŠ” ê³ ì •í•´ì„œ ì¶œë ¥í•˜ëŠ” `PromptTemplate`ì— ëŒ€í•œ ì‚¬ìš© ì˜ˆì‹œì´ë‹¤.
```py
from langchain import PromptTemplate
template = '{product}ë¥¼ í™ë³´í•˜ê¸° ìœ„í•œ ì¢‹ì€ ë¬¸êµ¬ë¥¼ ì¶”ì²œí•´ì¤˜?'

prompt = PromptTemplate(
    input_variables=['product'],
    template=template,
)

prompt.format(product="ì¹´ë©”ë¼")
```
- product ì— ì¹´ë©”ë¼ë¥¼ ì…ë ¥í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤€ë‹¤.
```
'ì¹´ë©”ë¼ë¥¼ í™ë³´í•˜ê¸° ìœ„í•œ ì¢‹ì€ ë¬¸êµ¬ë¥¼ ì¶”ì²œí•´ì¤˜?'
```

#### LLM í˜¸ì¶œ
- LLMì€ ì˜¤í”ˆAIì™€ êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•œë‹¤.
- í”„ë¡¬í”„íŠ¸ëŠ” 
  - 'ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤. ì§„í¬ê°€ í‚¤ìš°ëŠ” ë™ë¬¼ì€?'
- ì´ë©°, ì´ì— ë”°ë¼ ëª¨ë¸ì„ ê±°ì³ ë‚˜ì˜¤ëŠ” ê²°ê³¼ì¸ ì»´í”Œë¦¬ì…˜ì€ 'ê°•ì•„ì§€'ê°€ ë˜ì–´ì•¼ í•œë‹¤.
- ì˜¤í”ˆAIì—ì„œ ì œê³µí•˜ëŠ” `gpt-3.5-turbo` ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³¸ë‹¤.
- í•˜ì§€ë§Œ ê³¼ê¸ˆì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— llama3ë¥¼ ì‚¬ìš©í•˜ê² ë‹¤.
```py
from langchain_community.llms import Ollama

# ëª¨ë¸ ì„¤ì •
llm1 = Ollama(model='llama3')

# ì§ˆë¬¸ ì…ë ¥
question = "ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤. ì§„í¬ê°€ í‚¤ìš°ëŠ” ë™ë¬¼ì€? (ë‹µë³€ì€ í•œ ë‹¨ì–´ë¡œ ì¶œë ¥í•œë‹¤.)"

# ì‘ë‹µ ë°›ê¸°
response = llm1.invoke(question)

# ê²°ê³¼ ì¶œë ¥
print(response)
```
- ê²°ê³¼ê°€ ê°•ì•„ì§€ë¼ê³  ì •í™•íˆ ë³´ì—¬ì¤€ë‹¤.
```
ê°•ì•„ì§€
```
- ì´ë²ˆì—ëŠ” êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë¸ì„ ì‚´í´ë³¸ë‹¤.
- í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë¸ì€ ì£¼ë¡œ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ë¡œ ë‹¤ìŒ URLì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
- https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads

- ì˜ˆì œë¡œ ì§„í–‰í•  google/flan-t5-xxlëŠ” êµ¬ê¸€ì—ì„œ ê°œë°œí•œ T5 ëª¨ë¸ì˜ ë³€í˜• ì¤‘ í•˜ë‚˜ì´ë‹¤.
```py
from transformers import pipeline

model_id = 'google/flan-t5-small'
generator = pipeline('text2text-generation', model=model_id)

prompt = 'Q: ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤. ì§„í¬ê°€ í‚¤ìš°ëŠ” ë™ë¬¼ì€?\nA:'
completion = generator(prompt, max_length=20, temperature=0.7)

print(completion[0])
```
- ì‹¤í–‰ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì´ ë§¤ìš° ì´ìƒí•˜ë‹¤.
```
{'generated_text': 'a sexy sexy sexy sexy '}
```

#### ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
- ë­ì²´ì¸ì—ì„œ ì œê³µí•˜ëŠ” `ModelLaboratory`ë¥¼ ì´ìš©í•˜ë©´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•´ ë³¼ ìˆ˜ ìˆë‹¤.
```py
from langchain_community.llms import Ollama
from transformers import pipeline
from langchain.llms import HuggingFacePipeline
from langchain.model_laboratory import ModelLaboratory

# 1. Ollama LLM
llmi = Ollama(model="llama3")

# 2. Transformers pipeline â†’ LangChain LLM ë˜í•‘
hf_pipe = pipeline("text2text-generation", model="google/flan-t5-small")
llmii = HuggingFacePipeline(pipeline=hf_pipe)

# 3. Model Laboratoryë¡œ ë¹„êµ
model_lab = ModelLaboratory.from_llms([llmi, llmii])
model_lab.compare("ëŒ€í•œë¯¼êµ­ì˜ ê°€ì„ì€ ëª‡ ì›”ë¶€í„° ëª‡ ì›”ê¹Œì§€ì•¼?")
```
- ì‹¤í–‰ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
```
Input:
ëŒ€í•œë¯¼êµ­ì˜ ê°€ì„ì€ ëª‡ ì›”ë¶€í„° ëª‡ ì›”ê¹Œì§€ì•¼?

Ollama
Input:
ëŒ€í•œë¯¼êµ­ì˜ ê°€ì„ì€ ëª‡ ì›”ë¶€í„° ëª‡ ì›”ê¹Œì§€ì•¼?

Ollama
Params: {'model': 'llama3', 'format': None, 'options': {'mirostat': None, 'mirostat_eta': None, 'mirostat_tau': None, 'num_ctx': None, 'num_gpu': None, 'num_thread': None, 'num_predict': None, 'repeat_last_n': None, 'repeat_penalty': None, 'temperature': None, 'stop': None, 'tfs_z': None, 'top_k': None, 'top_p': None}, 'system': None, 'template': None, 'keep_alive': None, 'raw': None}
ğŸ˜Š

In South Korea, autumn (ê°€ì„) typically starts around late September to early October and lasts until late November to early December. So, the exact dates are:

* Start of autumn: around September 22nd to October 1st
* End of autumn: around November 20th to December 2nd

Note that these dates can vary slightly from year to year due to climate changes, but generally speaking, this is when South Korea experiences its autumn season. ğŸ‚

HuggingFacePipeline
Params: {'model_id': 'gpt2', 'model_kwargs': None, 'pipeline_kwargs': None}
```

#### ì¶œë ¥ íŒŒì„œ
- ë­ì²´ì¸ì—ì„œ ì œê³µí•˜ëŠ” ì¶œë ¥ íŒŒì„œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì´ ìˆë‹¤.
- `PydanticOutputParser`: ì…ë ¥ëœ ë°ì´í„°ë¥¼ ì •ì˜ëœ í•„ë“œ íƒ€ì…ì— ë§ê²Œ ìë™ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
- `SimpleJsonOutputParser`: JSON í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.
  - ì¶œë ¥ ê²°ê³¼ ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
```
[{'birthdate': 'Feburary 23, 1991', 'birthplace': 'Devon, England'}]
```
- `CommaSeperatedListOutputParser`: ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.
  - ì¶œë ¥ ê²°ê³¼ ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
```
['LG íŠ¸ìœˆìŠ¤,', 'ë‘ì‚° ë² ì–´ìŠ¤', 'KIA íƒ€ì´ê±°ì¦ˆ', 'SK ì™€ì´ë²ˆìŠ¤', 'ë¡¯ë° ìì´ì–¸ì¸ ']
```
- `DatetimeOutputParser`: ë‚ ì§œ/ì‹œê°„ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.
  - ì¶œë ¥ ê²°ê³¼ ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
```
1969-07-20 20:17:40
```
- `XMLOutputParser`: XML í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.
  - ì¶œë ¥ ê²°ê³¼ ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
```
{'teams': [{'team': 'LG twins'}, {'team': 'Doosan Bears'}, {'team': 'Kia Tigers'}, {'team': 'Samsung Lions'}, {'team': 'NC Dinos'}]}
```
- ì´ ì¤‘ì—ì„œ `CommaSeperatedListOutputParser`ë¡œ ì‘ì„±í•œ ì˜ˆì œë¥¼ í•˜ë‚˜ ì‚´í´ë³´ì.
- íŒŒì„œë¥¼ `CommaSeperatedListOutputParser`ë¡œ ì´ˆê¸°í™” í•œ í›„ ì¶œë ¥ í˜•ì‹ì„ ì§€ì •í•œë‹¤.
```py
from langchain.output_parsers import CommaSeparatedListOutputParser
from langchain.prompts import PromptTemplate
from langchain.llms import Ollama

llm = Ollama(model="llama3")

output_parser = CommaSeparatedListOutputParser()
format_instructions = output_parser.get_format_instructions()

prompt = PromptTemplate(
    template='7ê°œì˜ íŒ€ì„ ë³´ì—¬ì¤˜ {subject}.\n{format_instructions}',
    input_variables=['subject'],
    partial_variables={'format_instructions': format_instructions},
)
```
- ì´ì œ ì§€ì •ëœ `CommaSeparatedListOutputParser` ì¶œë ¥ì„ í™•ì¸í•´ë³´ê¸° ìœ„í•´ 'í•œêµ­ì˜ ì•¼êµ¬íŒ€ì€?' ì´ë¼ê³  ì§ˆì˜í•´ ë³¸ë‹¤.
```py
query = 'í•œêµ­ì˜ ì•¼êµ¬íŒ€ì€?'

output = llm(prompt.format(subject=query))

parsed_result = output_parser.parse(output)
print(parsed_result)
```
- ì¶œë ¥ì€ ì•„ë˜ì™€ ê°™ë‹¤.
```
['Here is the list of 7 Korean professional baseball teams:\n\nDoosan Bears', 'LG Twins', 'Kiwoom Heroes', 'KT Wiz', 'Hanwha Eagles', 'SK Wyverns', 'NC Dinos']
```

### 3-2. ë°ì´í„° ì—°ê²°
- ë°ì´í„° ì—°ê²°ì€ ì¼ë°˜ì ì¸ ë°ì´í„° ë¶„ì„ í™˜ê²½ì—ì„œ ETL (Extract, Transform, Load)ì— í•´ë‹¹í•œë‹¤.
- ETLì€ ë°ì´í„°ë¥¼ í•œ ê³³ì—ì„œ ë‹¤ë¥¸ ê³³ìœ¼ë¡œ ì˜®ê¸°ëŠ” ê³¼ì •ì„ ë§í•˜ë©°, ì„¸ ë‹¨ê³„ë¡œ ë‚˜ì›Œ ì§„í–‰í•œë‹¤.
1. ì¶”ì¶œ(extract) ë‹¨ê³„ì—ì„œëŠ” ì—¬ëŸ¬ ì¶œì²˜ë¡œë¶€í„° í•„ìš”í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
  - í”¼ì ë§Œë“¤ê¸°ë¥¼ ì˜ˆë¡œ ë“¤ë©´ ì¬ë£Œë¥¼ ì¤€ë¹„í•˜ëŠ” ë‹¨ê³„ë¡œ, ë‹¤ì–‘í•œ ì¥ì†Œì—ì„œ í† ë§ˆí† , ì¹˜ì¦ˆ, ë°€ê°€ë£¨ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒê³¼ ê°™ë‹¤.
2. ë³€í™˜(transform) ì‘ì—…ì—ì„œëŠ” ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í•„ìš”í•œ í˜•íƒœë¡œ ë³€í™˜í•œë‹¤.
  - í”¼ì ë§Œë“¤ê¸°ì—ì„œ ì‹¤ì œë¡œ ìš”ë¦¬ë¥¼ í•˜ëŠ” ë‹¨ê³„ë¡œ, í† ë§ˆí† ë¡œ ì†ŒìŠ¤ë¥¼ ë§Œë“¤ê³  ë°€ê°€ë£¨ë¡œ ë°˜ì£½í•´ì„œ ë„ìš°ë¥¼ ì¤€ë¹„í•˜ëŠ” ë‹¨ê³„ì´ë‹¤.
3. ì ì¬(load) ë‹¨ê³„ì—ì„œëŠ” ë³€í™˜ëœ ë°ì´í„°ë¥¼ ìµœì¢… ëª©ì ì§€ì¸ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ì— ì €ì¥í•œë‹¤.
  - í”¼ì ë§Œë“¤ê¸°ì—ì„œ í”¼ìë¥¼ ì˜¤ë¸ì— êµ¬ìš´ í›„, ì™„ì„±ëœ í”¼ìë¥¼ í…Œì´ë¸” ìœ„ì— ì˜¬ë¦¬ëŠ” ê³¼ì •ì´ë‹¤.

- ë°ì´í„° ì—°ê²°ì˜ êµ¬ì„± ìš”ì†Œ:
- ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (document loaders):
  - ë‹¤ì–‘í•œ ì¶œì²˜ì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒìœ¼ë¡œ, ETLì—ì„œ ì¶”ì¶œ(extract)ì— í•´ë‹¹í•œë‹¤.
- ë¬¸ì„œ ë³€í™˜ (document transformers):
  - ì…ë ¥ ë°ì´í„°ë¥¼ ì²­í¬(chunk)ë¡œ ë¶„í• í•˜ê±°ë‚˜ ë‹¤ì‹œ ê²°í•©í•˜ëŠ” ì‘ì—…, í•„í„°ë§ ì‘ì—… ë“±ì„ ì‰½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
  - ETLì—ì„œ ë³€í™˜(transform)ì— í•´ë‹¹í•œë‹¤.
- ë¬¸ì„œ ì„ë² ë”© (embedding model):
  - ë³µì¡í•œ ë°ì´í„°ë¥¼ ê°„ë‹¨í•œ í˜•íƒœ(ë²¡í„°)ë¡œ ë³€í™˜í•œë‹¤.
- ë²¡í„° ì €ì¥ì†Œ (vector stores):
  - ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ë³€í™˜ëœ ë²¡í„°ë¥¼ ì €ì¥/ê´€ë¦¬/ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
  - ETLì—ì„œ ì ì¬(load)ì— í•´ë‹¹í•œë‹¤.
- ê²€ìƒ‰ê¸° (retriverse):
  - ì–¸ì–´ ëª¨ë¸ê³¼ ê²°í•©í•  ê´€ë ¨ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ê²ƒìœ¼ë¡œ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ ì—­í• ì„ í•œë‹¤.

#### íŒŒì´ì¬ì—ì„œ ì‹¤í–‰í•´ë³´ê¸°
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤.
```py
!pip install langchain
!pip install openai
!pip install pypdf
!pip install faiss-cpu
!pip install sentence-transformers
```
- `pypdf`:
  - íŒŒì´ì¬ì—ì„œ PDF íŒŒì¼ì„ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.
  - PDF íŒŒì¼ì„ ì½ê±°ë‚˜ ìˆ˜ì •í•  ë•Œ ì‚¬ìš©í•œë‹¤.
- `tiktoken`:
  - ì˜¤í”ˆAIì—ì„œ ì œê³µí•˜ëŠ” ì„ë² ë”©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.
  - `OpenAIEmbeddings`ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•˜ë‹¤.
- `faiss-cpu`:
  - í˜ì´ìŠ¤ë¶ì˜ AI ì—°êµ¬íŒ€ì´ ê°œë°œí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë²¡í„°ì˜ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìœ„í•´ ì‚¬ìš©í•œë‹¤.
  - ì‚¬ìš© ì»´í“¨í„°ê°€ GPUë¥¼ ì§€ì›í•œë‹¤ë©´, `!pip install faiss-gpu`ë¡œ ì„¤ì¹˜í•œë‹¤.
- `sentence-transformers`:
  - ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë¬¸ì¥ ë˜ëŠ” ë‹¨ë½ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.

#### PDF íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
- "The_Adventures_of_Tom_Sawyer.pdf"ë¥¼ ì‚¬ìš©í•˜ì—¬ `PyPDFLoader`ë¥¼ ì´ìš©í•´ì„œ ë¶ˆëŸ¬ì˜¨ë‹¤.
```py
from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("C:/Users/ryuta/PycharmProjects/JupyterProject/data/The_Adventures_of_Tom_Sawyer.pdf")
document = loader.load()
document[5].page_content[:5000]
```
- ì½”ë“œì—ì„œ `document[5].page_content[:5000]`ì˜ ì˜ë¯¸ëŠ” PDF 6í˜ì´ì§€ ì¤‘ 5,000 ê¸€ìë¥¼ ì½ì–´ì˜¤ë¼ëŠ” ì˜ë¯¸ì´ë‹¤.
- ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ì´ ëœë‹¤.
```
'Chapter 1    The Fence \n \nTom Sawyer lived with his aunt because his mother and \nfather were dead. Tom didnâ€™t like going to school, and he \ndidnâ€™t like working. He liked playing and having \nadventures. One Friday, he didnâ€™t go to schoolâ€”he went \nto the river. \nAunt Polly was angry. â€œYouâ€™re a bad boy!â€ she said. \nâ€œTomorrow you canâ€™t play with your friends because you \ndidnâ€™t go to school today. Tomorrow youâ€™re going to work \nfor me. You can paint the fence.â€ \nSaturday morning, Tom was not happy, but he started to \npaint the fence. His friend Jim was in the street. \nTom asked him, â€œDo you want to paint?â€ \nJim said, â€œNo, I canâ€™t. Iâ€™m going to get water.â€ \nThen Ben came to Tomâ€™s house. He watched Tom and \nsaid, â€œIâ€™m going to swim today. You canâ€™t swim because \nyouâ€™re working.â€ \nTom said, â€œThis isnâ€™t work. I like painting.â€ \nâ€œCan I paint, too?â€ Ben asked. \nâ€œNo, you canâ€™t,â€ Tom answered. â€œAunt Polly asked me \nbecause Iâ€™m a very good painter.â€ \nBen said, â€œIâ€™m a good painter, too. Please, can I paint? I \nhave some fruit. Do you want it?â€ \nOK,â€ Tom said. â€œGive me the fruit. Then you can paint.â€ \nBen started to paint the fence. Later, many boys came to \nTomâ€™s house. They watched Ben, and they wanted to \npaint, too. \nTom said, â€œGive me some food and you can paint.â€ \n \n1 '
```

#### ì„ë² ë”© ì²˜ë¦¬
- ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìœ¼ë‹ˆ ì´ì œ ì„ë² ë”© ì²˜ë¦¬ë¥¼ í•œë‹¤.
- ì˜¤í”ˆAIì—ì„œ ì œê³µí•˜ëŠ” ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©°, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ íŒŒì´ìŠ¤ë¥¼ ì‚¬ìš©í•œë‹¤.
```py
import os
os.environ['OPENAI_API_KEY'] = 'openai_api_key'

from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
db = FAISS.from_documents(document, embeddings)
```
- í•˜ì§€ë§Œ ê³¼ê¸ˆ ë°œìƒ ë•Œë¬¸ì— í—ˆê¹…í˜ì´ìŠ¤ë¡œ ì§„í–‰í•˜ê² ë‹¤.
```py
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/paraphrase-MiniLM-L6-v2')
db = FAISS.from_documents(document, embeddings)

text = 'ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤. ì§„í¬ê°€ í‚¤ìš°ê³  ìˆëŠ” ë™ë¬¼ì€?'
text_embeddings = embeddings.embed_query(text)
print(text_embeddings)
```
- ê²°ê³¼ë¡œ ìˆ«ìë“¤ì˜ ë‚˜ì—´ì¸ ë²¡í„°ë¡œ ë³€í™˜ë˜ì–´ ì¶œë ¥ëœë‹¤.
```
[0.34980088472366333, 0.43030020594596863, 0.006742554251104593, -0.4293422996997833, 0.1396116316318512, 0.7362887859344482, 0.7675184011459351, -0.1013602465391159, 0.015650469809770584, -0.4876149594783783, 0.08206877112388611, -0.7641611695289612, -0.06242436170578003, 0.3863333463668823, 0.19249878823757172, 0.09351189434528351, -0.2836340367794037, 0.43225806951522827, -1.0121886730194092, 0.1022379919886589, 0.19609734416007996, -0.05373897776007652, 0.4707782566547394, -0.10462331026792526,
...ì¤‘ëµ...
0.0017677649157121778, -0.1239648386836052, 0.5256860256195068, 1.8278582096099854, 0.1426382213830948, -0.13094964623451233, 0.48978206515312195, -0.863854169845581, -0.14400769770145416, 0.27787792682647705, -0.3267405927181244, 0.13500145077705383, 0.5196707248687744, 0.05651252716779709, 0.07641520351171494, 0.0680074691772461, 0.0593317374587059, 0.19598136842250824, -0.9727583527565002, 0.09746786206960678, 0.6688352823257446, -0.6109157800674438, 0.47462794184684753, 0.6356025338172913]
```

#### ê²€ìƒ‰ê¸° í™œìš©
- ì›í•˜ëŠ” ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ ê²€ìƒ‰ê¸°(RetrievalQA)ë¥¼ í™œìš©í•œë‹¤.
- 'ë§ˆì„ ë¬´ë¤ì— ìˆë˜ ë‚¨ìë¥¼ ì£½ì¸ ì‚¬ëŒì€ ëˆ„êµ¬ë‹ˆ?'ë¼ê³  ë¬¼ì–´ë³¸ë‹¤.
```py
from langchain.llms import Ollama
llm = Ollama(model='llama3')

from langchain.chains import RetrievalQA
retriever = db.as_retriever()

qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type='stuff',
    retriever=retriever
)

query = 'ë§ˆì„ ë¬´ë¤ì— ìˆë˜ ë‚¨ìë¥¼ ì£½ì¸ ì‚¬ëŒì€ ëˆ„êµ¬ë‹ˆ?'
result = qa({'query': query})
print(result['result'])
```
- ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤.
```
According to the story, Injun Joe killed the doctor in the graveyard. Therefore, my answer is:

Injun Joe.
```

### 3-3. ì²´ì¸
- ì²´ì¸(chain)ì€ ë§ ê·¸ëŒ€ë¡œ ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œë¥¼ ì¡°í•©í•´ì„œ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.
- í…ìŠ¤íŠ¸ê°€ ì…ë ¥ë˜ë©´ LLM1ê³¼ LLM2ë¥¼ ê±°ì³ì„œ í…ìŠ¤íŠ¸ê°€ ìƒì„±ë˜ëŠ” ì¼ë ¨ì˜ ê³¼ì •ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì²´ì¸ì´ë‹¤.

#### íŒŒì´ì¬ì—ì„œ ì‹¤í–‰í•´ë³´ê¸°
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤.
```py
!pip install langchain
!pip install openai
```
- ì¼ë°˜ì ìœ¼ë¡œ ì²´ì¸ì€ `LLMChain`ì„ ì‚¬ìš©í•œë‹¤.
- `LLMChain`ì„ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•˜ê²Œ í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì„ ì—°ê²°í•œë‹¤.
```py
from langchain.chains import LLMChain
from langchain import PromptTemplate
from langchain.llms import Ollama

llm = Ollama(model='llama3')

prompt = PromptTemplate(
    input_variables=['country'],
    template='{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?',
)

chain = LLMChain(llm=llm, prompt=prompt)
chain.run('ëŒ€í•œë¯¼êµ­')
```
- ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
```
'ğŸ˜Š\n\nThe capital of South Korea (ëŒ€í•œë¯¼êµ­) is Seoul (ì„œìš¸).'
```
- ì´ë²ˆì—ëŠ” ì¢€ ë” ë³µì¡í•œ ì²´ì¸ì„ ë§Œë“¤ì–´ë³¸ë‹¤.
- `SequentialChain`ì„ ì‚¬ìš©í•´ ì²´ì¸ ë‘ê°œë¥¼ ì—°ê²°í•˜ê³ , `output_key`ë¥¼ ì‚¬ìš©í•´ ê°ê°ì˜ ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤.
```py
# í”„ë¡¬í”„íŠ¸1 ì •ì˜
prompt1 = PromptTemplate(
    input_variables=['sentence'],
    template='ë‹¤ìŒ ë¬¸ì¥ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ì„¸ìš”.\n\n{sentence}'
)

# ë²ˆì—­(ì²´ì¸1)ì— ëŒ€í•œ ëª¨ë¸
chain1 = LLMChain(llm=llm, prompt=prompt1, output_key='translation')

# í”„ë¡¬í”„íŠ¸2 ì •ì˜
prompt2 = PromptTemplate.from_template(
    'ë‹¤ìŒ ë¬¸ì¥ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n\n{translation}'
)

# ìš”ì•½(ì²´ì¸2)ì— ëŒ€í•œ ëª¨ë¸
chain2 = LLMChain(llm=llm, prompt=prompt2, output_key='summary')

from langchain.chains import SequentialChain
all_chain = SequentialChain(
    chains=[chain1, chain2],
    input_variables=['sentence'],
    output_variables=['translation', 'summary'],
)

# ë²ˆì—­í•˜ê³  ìš”ì•½í•´ì•¼ í•  ì˜ì–´ ë¬¸ì¥
sentence='''
One limitation of LLMs is their lack of contextual information (e.g., access to some specific documents or emails). You can combat this by giving LLMs access to the specific external data. For this, you first need to load the external data with a document loader. LangChain provides a variety of loaders for different types of documents ranging from PDFs and emails to websites and YouTube videos.
'''
all_chain(sentence)
```
- ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì˜ì–´ ë¬¸ì¥ì„ í•œê¸€ë¡œ ë²ˆì—­í•œ í›„ ê·¸ ë¬¸ì¥ì„ ë‹¤ì‹œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ ë³´ì—¬ì¤€ë‹¤.
```
{'sentence': '\nOne limitation of LLMs is their lack of contextual information (e.g., access to some specific documents or emails). You can combat this by giving LLMs access to the specific external data. For this, you first need to load the external data with a document loader. LangChain provides a variety of loaders for different types of documents ranging from PDFs and emails to websites and YouTube videos.\n',
 'translation': 'LLMsì˜ í•œ ì œí•œì€ íŠ¹ì • ë¬¸ì„œë‚˜ ì´ë©”ì¼ì— ëŒ€í•œ ì½˜í…ìŠ¤íŠ¸ ì •ë³´ì˜ ë¶€ì¡±ì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ LLMsì— ì™¸ë¶€ ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ê²ƒì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” ë¨¼ì € ì™¸ë¶€ ë°ì´í„°ë¥¼ ë¬¸ì„œ ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. LangChainì€ ë‹¤ì–‘í•œ ë¬¸ì„œ ìœ í˜•(ì˜ˆ, PDF, ì´ë©”ì¼, ì›¹ì‚¬ì´íŠ¸, ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ë“±)ì—ê²Œ ì í•©í•œ ë¡œãƒ¼ãƒ€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.',
 'summary': 'Here is a summary of the sentence:\n\nLLMs have a limitation in lacking context information about specific documents or emails. This can be addressed by allowing LLMs to access external data, which requires loading external data using a document loader. LangChain provides various loaders suitable for different types of documents (e.g., PDF, email, website, YouTube video).'}
```

### 3-4. ë©”ëª¨ë¦¬
- ë©”ëª¨ë¦¬(memory)ëŠ” ë§ ê·¸ëŒ€ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê³µê°„ì´ë‹¤.
- ì´ë•Œ ë°ì´í„°ë¼ê³  í•˜ë©´ ëŒ€í™” ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë°ì´í„°ë¥¼ ì˜ë¯¸í•œë‹¤.
- íŠ¹íˆ ì±—ë´‡ ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê²½ìš° ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•´ì•¼ í•˜ì§€ë§Œ LLMì€ ê¸°ë³¸ì ìœ¼ë¡œ ì±„íŒ… ê¸°ë¡ì„ ì¥ê¸°ì ìœ¼ë¡œ ë³´ê´€í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ì´ëŸ¬í•œ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ê²ƒì„ ë„ì™€ì£¼ëŠ” ê²ƒì´ ë©”ëª¨ë¦¬ì´ë‹¤.
- ëŒ€í™” ë‚´ìš© ì €ì¥ í˜•íƒœ:
  - ëª¨ë“  ëŒ€í™” ìœ ì§€
  - ìµœê·¼ kê°œì˜ ëŒ€í™” ìœ ì§€
  - ëŒ€í™”ë¥¼ ìš”ì•½í•˜ì—¬ ìœ ì§€

#### íŒŒì´ì¬ì—ì„œ ì‹¤í–‰í•´ë³´ê¸°
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤.
```py
!pip install langchain
!pip install openai
```
- ì•ì—ì„œì˜ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•´ì„œ ë‹µë³€ì„ ì œê³µí•˜ê¸° ìœ„í•´ `ConversationChain`ì„ ì‚¬ìš©í•œë‹¤.
```py
from langchain.llms import Ollama
llm = Ollama(model='llama3')

from langchain import ConversationChain
conversation = ConversationChain(llm=llm, verbose=True)

conversation.predict(input='ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í•œ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.')
conversation.predict(input='ì˜ìˆ˜ëŠ” ê³ ì–‘ì´ë¥¼ ë‘ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.')
conversation.predict(input='ì§„í¬ì™€ ì˜ìˆ˜ê°€ í‚¤ìš°ëŠ” ë™ë¬¼ì€ ì´ ëª‡ ë§ˆë¦¬?')
```
- ì•ì—ì„œ í–ˆë˜ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í–ˆë‹¤ê°€ ë§ˆì§€ë§‰ ì§ˆë¬¸ì— ë‹µë³€ì„ í•œë‹¤.
```
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:

Human: ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í•œ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.
AI:

> Finished chain.
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
Human: ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í•œ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.
AI: Fascinating! So, Jin-hee has one dog that she's raising, huh? That's great! According to my vast knowledge database, Jin-hee is a fictional character from the popular Korean drama "Crash Landing on You" (2019-2020). And in this context, it's not explicitly stated how many dogs Jin-hee owns or raises. However, I can tell you that Jin-hee is a North Korean army officer who falls in love with a South Korean heiress, Yoon Se-ri. The drama explores their romance amidst the complexities of the Korean Peninsula's divided politics. Would you like to know more about the show?
Human: ì˜ìˆ˜ëŠ” ê³ ì–‘ì´ë¥¼ ë‘ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.
AI:

> Finished chain.
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
Human: ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í•œ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.
AI: Fascinating! So, Jin-hee has one dog that she's raising, huh? That's great! According to my vast knowledge database, Jin-hee is a fictional character from the popular Korean drama "Crash Landing on You" (2019-2020). And in this context, it's not explicitly stated how many dogs Jin-hee owns or raises. However, I can tell you that Jin-hee is a North Korean army officer who falls in love with a South Korean heiress, Yoon Se-ri. The drama explores their romance amidst the complexities of the Korean Peninsula's divided politics. Would you like to know more about the show?
Human: ì˜ìˆ˜ëŠ” ê³ ì–‘ì´ë¥¼ ë‘ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.
AI: Another pet owner in the world of K-dramas! According to my knowledge, Yoon Se-ri (played by Son Ye-jin) is a South Korean heiress who accidentally lands her parachute in North Korea and falls in love with Jin-hee. And now you're telling me that Yoon Se-ri has two cats that she's raising? That's wonderful! While I don't have specific information about the number of pets Yoon Se-ri owns, I can tell you that her relationship with Jin-hee is a central plot point in the drama "Crash Landing on You". The show explores themes of love, culture, and politics as these two characters from different worlds navigate their feelings for each other. Would you like to know more about Yoon Se-ri's character or the show in general?
Human: ì§„í¬ì™€ ì˜ìˆ˜ê°€ í‚¤ìš°ëŠ” ë™ë¬¼ì€ ì´ ëª‡ ë§ˆë¦¬?
> Finished chain.
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
Human: ì§„í¬ëŠ” ê°•ì•„ì§€ë¥¼ í•œ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.
AI: Fascinating! So, Jin-hee has one dog that she's raising, huh? That's great! According to my vast knowledge database, Jin-hee is a fictional character from the popular Korean drama "Crash Landing on You" (2019-2020). And in this context, it's not explicitly stated how many dogs Jin-hee owns or raises. However, I can tell you that Jin-hee is a North Korean army officer who falls in love with a South Korean heiress, Yoon Se-ri. The drama explores their romance amidst the complexities of the Korean Peninsula's divided politics. Would you like to know more about the show?
Human: ì˜ìˆ˜ëŠ” ê³ ì–‘ì´ë¥¼ ë‘ ë§ˆë¦¬ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.
AI: Another pet owner in the world of K-dramas! According to my knowledge, Yoon Se-ri (played by Son Ye-jin) is a South Korean heiress who accidentally lands her parachute in North Korea and falls in love with Jin-hee. And now you're telling me that Yoon Se-ri has two cats that she's raising? That's wonderful! While I don't have specific information about the number of pets Yoon Se-ri owns, I can tell you that her relationship with Jin-hee is a central plot point in the drama "Crash Landing on You". The show explores themes of love, culture, and politics as these two characters from different worlds navigate their feelings for each other. Would you like to know more about Yoon Se-ri's character or the show in general?
Human: ì§„í¬ì™€ ì˜ìˆ˜ê°€ í‚¤ìš°ëŠ” ë™ë¬¼ì€ ì´ ëª‡ ë§ˆë¦¬?
AI:

> Finished chain.
'A question that gets to the heart of our conversation! As I\'ve mentioned earlier, Jin-hee is said to have one dog, and Yoon Se-ri has two cats. So, if we add those up, they are raising a total of three animals. However, please note that this information is specific to their fictional characters in the drama "Crash Landing on You" and might not reflect real-life pet ownership. Would you like to know more about the show or its characters?'
```

### 3-5. ì—ì´ì „íŠ¸/íˆ´
- LLMì´ ë§¤ìš° ê°•ë ¥í•œ ëª¨ë¸ì„ì—ëŠ” ë¶„ëª…í•˜ì§€ë§Œ ì—¬ê¸°ì—ë„ í•œê³„ê°€ ìˆë‹¤.
- ë°”ë¡œ í•™ìŠµì„ ë§ˆì¹œ ê·¸ ì‹œì  ì´í›„ì˜ ì‚¬ê±´ì´ë‚˜ ì‚¬ì‹¤ì— ëŒ€í•´ì„œëŠ” ì •ë³´ê°€ ì „í˜€ ì—†ë‹¤ëŠ” ê²ƒì´ë‹¤.
- ë˜í•œ ì¼ë°˜ì ì¸ ë°ì´í„°ë¡œ í•™ìŠµí–ˆê¸° ë•Œë¬¸ì— íŠ¹ì • ì‚°ì—…ì— ëŒ€í•´ íŠ¹í™”ë˜ì–´ ìˆì§€ë„ ì•Šë‹¤.
- ì´ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì´ ì—ì´ì „íŠ¸ì™€ íˆ´ì´ë‹¤.
- ì—ì´ì „íŠ¸ëŠ” LLMì„ ì´ìš©í•´ì„œ ì–´ë–¤ ì‘ì—…ì„ ì–´ë–¤ ìˆœì„œë¡œ ìˆ˜í–‰í• ì§€ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•˜ëŠ”ë°, ì´ ì‘ì—…ì— íˆ´ì´ë¼ëŠ” ê²ƒì„ ì‚¬ìš©í•œë‹¤.
- íˆ´ì€ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë„êµ¬ë¡œ, ìœ„í‚¤í”¼ë””ì•„ë‚˜ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ë¹™ ì²˜ëŸ¼ LLM ì´ì™¸ì˜ ë‹¤ë¥¸ ë¦¬ì†ŒìŠ¤ë¥¼ ì˜ë¯¸í•œë‹¤.
- 'íˆ´ì„ ì´ìš©í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•œë‹¤.'ëŠ” ë§ì´ë‹¤.

#### íŒŒì´ì¬ì—ì„œ ì‹¤í–‰í•´ë³´ê¸°
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤.
```py
!pip install langchain
!pip install wikipedia
!pip install numexpr
```
- ìœ„í‚¤í”¼ë””ì•„ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë‹¤.
- `numexpr` ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì—°ì‚°ì„ ìœ„í•´ ì‚¬ìš©í•œë‹¤.
- ì—ì´ì „íŠ¸ê°€ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì—ë“œ ì‹œëŸ°ì˜ ìƒë…„ì›”ì¼ì„ ì¡°íšŒí•œ í›„ ê³„ì‚°ê¸°ë¥¼ í†µí•´ ë‚˜ì´ë¥¼ ê³„ì‚°í•˜ëŠ” ì˜ˆì œì´ë‹¤.
```py

```
