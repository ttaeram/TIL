# What does CLIP know about a red circle? Visual pr mpt engineering for VLMs

## 01. Abstract
CLIP과 같은 대규모 VLM은 강력한 이미지-텍스트 표현을 학습하며, 이는 zero-shot 분류에서 텍스트-이미지 생성에 이르기까지 다양한 응용 분야에서 활용된다. 프롬프팅을 통해 새로운 판별 작업을 해결하는 능력은 GPT-3와 같은 대규모 언어 모델에 비해 뒤쳐진다. 여기서는 텍스트 대신 이미지 공간에서 편집하여 분류를 넘어 컴퓨터 비전 작업을 해결하기 위한 시각적 프롬프트 엔지니어링 아이디어를 제안한다. 특히, CLIP의 새로운 능력을 발견했는데, 단순히 객체 주위에 빨간 원을 그리는 것만으로도 모델의 주의를 해당 영역으로 유도하면서도 전역 정보를 유지할 수 있다. zero-shot referring expressions comprehension에서 최첨단 성능을 달성하고 키포인트 localizaiton 작업에서 강력한 성능을 보여줌으로써 이 간단한 접근 방식의 강력함을 입증한다. 마지막으로, 대규모 언어-비전 모델의 잠재적인 윤리적 문제에 주의를 환기시킨다.

## 02. Related work
### Emergent Behaviour from Large Scale Pretraining
대규모 사전 훈련에서 emergent behavior는 주로 LLM에서 관찰되었다. 특히 GPT-2, GPT-3 및 ChatGPT는 zero-shot 번역, 질문 응답, 산술, 그리고 embodied agent를 위한 행동 계획과 같은 작업을 수행할 수 있는 것으로 나타났다. LLM을 fine-tuning하면 docstring에서 코드를 생성하거나 수학 문제를 해결할 수 있는 모델이 생성될 수도 있다. CLIP과 같은 VLM에 대해 보고된 emergent zero-shot behavior는 거의 없으며 주로 분류 및 OCR에 대한 것이다. FLAMINGO 및 BLIP과 같은 생성적 VLM은 캡션 생성 및 시각적 질문 응답 작업에서 뛰어나지만 픽셀 수준의 컴퓨터 비전 문제를 해결할 방법은 없다.

### Prompting VLMs
VLM 프롬프팅은 일반적으로 고정된 CLIP 모델이 원하는 작업을 쉽게 해결하도록 유도하기 위해 학습 가능한 토큰 세트를 텍스트 입력, 비전 입력 또는 텍스트 및 비전 입력 모두에 추가하여 수행된다. 이미지 주변의 패딩 또는 이미지 패치 변경과 같이 픽셀 공간에서 증강을 학습하며, 이를 다운스트림 작업에서 경사 하강법으로 최적화하는 논문이 존재한다. 이미지 inpainting을 학술 논문의 그림에서 훈련된 생성 모델을 사용하여 시각적 프롬프팅 작업으로 캐스팅하는 논문도 있다. 이미지 영역 색칠은 모델이 주석이 달린 이미지에서 fine-tuning되는 VCR 작업에 사용되었다. Colorful Prompt Tuning(CPT)은 이미지 영역을 색칠하고 캡션 모델을 사용하여 표현식이 이미지에서 어떤 객체를 지칭하는지 색상을 예측하여 예측헌다. CPT와 유사하게 본 논문은 픽셀 공간에서 입력 이미지를 증강하고 zero-shot 추론을 수행한다. 그러나 저자는 이미지를 인간과 유사한 방식으로 주석을 달고 이를 통해 저자의 방법이 CPT보다 더 강력하고 유연하다는 것을 보인다.

### Referring Expression Comprehension
Referring Expression Comprehension(REC)은 텍스트 설명에 해당하는 이미지에서 대상 객체를 localization하는 것을 목표로 한다. REC에 대한 대부분의 접근 방식은 예를 들어 Faster-RCNN으로 생성된 객체 제안으로 시작하여 이를 점수화하는 방법을 학습한다. REC는 때때로 주어진 영역에 대한 설명을 생성하는 작업인 referring expression generation과 함께 고려됩니다. 생성기를 안내하기 위해 comprehension 모델을 사용하는 방법도 있고, 감지기를 캡션 생성기와 공동으로 훈련하는 방법도 있다. 한편, 이해 모델을 사용하여 생성기를 안내하거나, 검출기와 캡션 생성기를 공동으로 학습하기도 한다. 일부 연구에서는 장면을 그래프로 모델링하거나 언어 파서 및 문법 기반 방법을 사용하여 해석 가능한 결과를 얻는다. 최근에는 transformer 아키텍처가 사용되었다. transformer 디코더가 지칭 표현을 입력으로 받아 경계 상자를 예측하는 텍스트 조절 객체 검출을 수행하는 방법도 있다. 텍스트 기반 분할 또는 검출을 테스트 시간에 수행할 수 있도록 텍스트-픽셀 간의 대조 손실을 사용하여 학습하는 방법도 있다.

### Unsupervised Referring Expression Comprehension
Unsupervised Referring Expression Comprehension은 CLIP과 같은 대규모 사전 훈련 모델의 도입으로 가능해진, 덜 연구된 영역이다. ReCLIP은 객체 제안을 잘라내고 CLIP을 사용하여 순위를 매긴 다음, 왼쪽/오른쪽, 더 작음/더 큼 등과 같은 관계를 고려하기 위해 임시 사후 처리 단계를 거친다. CPT는 객체 제안 상자에 색상을 지정하고 사전 훈련된 캡션 모델을 사용하여 어떤 색상의 제안이 쿼리 설명에 해당하는지 자동 회귀적으로 예측한다. Pseudo-Q는 이미지에서 여러 객체에 대한 설명을 생성하고, 이는 REC 네트워크를 학습하는 데 사용된다. 그러나 이 모델은 COCO에서 학습된 캡션 모델을 사용하여 생성된 의사 설명을 사용하므로 완전히 비지도 학습 방식은 아니다.

### Visual Reasoning Using Large Pretrained Models
대규모 사전 훈련 모델을 사용한 Visual Reasoning은 지난 몇 년 동안 큰 관심을 받아온 분야이다. 지칭 표현 검출 외에도 CLIP은 시맨틱 분할에 사용되었다. GAN의 잠재 공간에서 부분 공동 분할을 수행한 후 CLIP을 사용하여 객체 부분에 텍스트 레이블을 할당하는 연구가 있다. 범용 마스크 제안 네트워크와 CLIP을 분류기로 사용하여 open-vocabulary 분할에 CLIP을 활용하기도 한다. CLIP은 또한 비지도 객체 제안 생성 및 open-set 검출에도 사용되었다. 시맨틱 분할은 이미지 전용 또는 이미지-텍스트 자기 지도 학습에서도 나타난다.

### Bias of VLMs
VLM의 편향은 다운스트림 애플리케이션이 학습 데이터에 존재하는 편향과 고정관념을 영속화할 위험이 있으므로 점점 더 인기 있는 연구 분야이다. 그러나 VLM의 편향을 평가하는 방법은 아직 제대로 확립되지 않았다. 인종이 다른 사람들의 얼굴을 비인간 및 범죄 범주로 잘못 분류하는 CLIP의 오류율을 측정하는 연구, 검색 결과의 공정성을 측정하는 연구가 있다. 본 논문에서 사람 위에 빨간색 원을 추가하면 부정적인 의미를 유발할 수 있는 또 다른 종류의 편향을 보여준다.

## 05. Conclusions
본 논문은 마킹을 통한 시각적 프롬프트 엔지니어링이 zero-shot 방식으로 CLIP과 같은 VLM으로부터 유용한 동작을 추출할 수 있으며, 최첨단 zero-shot referring expression comprehension 성능을 달성하고 이미지 자르기와 같은 기존 기술보다 훨씬 뛰어난 성능을 보임을 입증했다. 논문의 분석에 따르면 이러한 동작은 VLM의 훈련 데이터에 마킹 관련 샘플이 존재하지만 이러한 샘플이 매우 드물기 때문에 나타나는 것으로 보인다. 결과적으로, 이러한 동작은 매우 큰 데이터 세트로 훈련된 매우 큰 모델에서만 학습할 수 있다. 또한 분석 결과, VLM은 바람직하지 않은 동작도 습득하는데, 이미지에 빨간색 원을 추가하는 것만으로도 해당 이미지가 부정적인 의미를 갖는다는 모델의 믿음이 증가하는 것으로 나타났다.

### Dataset Ethics
논문에서 RefCOCO, RefCOCO+, MSCOCO, FaceSynthetics, YFCC15M, CUB, SPair71k를 해당 약관에 부합하는 방식으로 사용한다. 이러한 이미지 중 일부는 개인 데이터(얼굴)를 포함할 수 있다. 4-4절에서 사전 훈련된 CLIP 모델의 편향으로 인해 그러한 방법이 사람에 대한 정보를 안정적으로 추출할 수 없음을 입증하기 위해 MS-COCO를 사용한다. 동일한 목적으로 사용되는 FaceSynthetics는 합성 얼굴 데이터 세트이므로 개인 정보 보호 문제를 제기하지 않는다. 윤리, 데이터 보호 및 저작권에 대한 자세한 내용은 https://www.robots.ox.ac.uk/~vedaldi/research/union/ethics.html 에서 확인할 수 있다.
